{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b50a0d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator\n",
    "from agno.agent import Agent, RunResponse\n",
    "from agno.models.openai.like import OpenAILike\n",
    "from agno.utils.pprint import pprint_run_response\n",
    "from agno.vectordb.lancedb import LanceDb\n",
    "from agno.vectordb.search import SearchType\n",
    "from agno.embedder.openai import OpenAIEmbedder\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "api_key=os.getenv(\"QWEN_API_KEY\")\n",
    "base_url=os.getenv(\"QWEN_API_BASE_URL\")\n",
    "local_base_url = 'http://192.168.0.166:8000/v1'\n",
    "local_model_name = 'Qwen3-235B'\n",
    "model_name = 'qwen-plus-latest'\n",
    "embedding_model_id = 'text-embedding-v3'\n",
    "\n",
    "local_settings = {\n",
    "  'api_key' : '123',\n",
    "  'base_url' : local_base_url,\n",
    "  'id' : local_model_name\n",
    "}\n",
    "\n",
    "qwen_settings = {\n",
    "  'api_key' : api_key,\n",
    "  'base_url' : base_url,\n",
    "  'id' : model_name\n",
    "}\n",
    "\n",
    "settings = qwen_settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fff8fb3",
   "metadata": {},
   "source": [
    "## 1. 设置向量数据库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d5d879f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db = LanceDb(\n",
    "    table_name=\"base_vectors\",\n",
    "    uri=\"tmp/lancedb\",\n",
    "    search_type=SearchType.hybrid,\n",
    "    embedder=OpenAIEmbedder(id=embedding_model_id,api_key=api_key,base_url=base_url, dimensions=1024),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022d6c9c",
   "metadata": {},
   "source": [
    "### 1.1 填充向量数据库（根据不同的文件类型，调用对应的向量数据库，然后作为上下文检索提供给LLM）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f160ff68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agno.knowledge.website import WebsiteKnowledgeBase\n",
    "knowledge_base = WebsiteKnowledgeBase(\n",
    "    urls=[\"https://docs.agno.com/introduction\"],\n",
    "    # Number of links to follow from the seed URLs\n",
    "    max_links=10,\n",
    "    # Table name: ai.website_documents\n",
    "    vector_db=vector_db,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bacde9",
   "metadata": {},
   "source": [
    "第一次运行的时候相当于从源中读取数据加载到向量数据库中，所以只需要执行一次，数据库中就存储了相关数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82c5d633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Loading knowledge base                                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Loading knowledge base                                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "knowledge_base.load(recreate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c722a6a",
   "metadata": {},
   "source": [
    "## 2. 加载数据库\n",
    "\n",
    "使用基类`AgentKnowledge`即可完成任一数据库的加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29a5a38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agno.knowledge import AgentKnowledge\n",
    "knowledge = AgentKnowledge(vector_db=vector_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee6f02bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(model=OpenAILike(**settings),knowledge=knowledge,telemetry=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "427b1ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Found <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> documents                                                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Found \u001b[1;36m5\u001b[0m documents                                                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = agent.run(message='what is agno?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "465493c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agno is a full-stack framework for building Multi-Agent Systems with memory, knowledge, and reasoning capabilities. It is designed to help engineers and researchers develop agentic systems across five levels of complexity:\n",
      "\n",
      "1. **Level 1**: Agents with tools and instructions.\n",
      "2. **Level 2**: Agents with knowledge and storage.\n",
      "3. **Level 3**: Agents with memory and reasoning.\n",
      "4. **Level 4**: Agent teams that can reason and collaborate.\n",
      "5. **Level 5**: Agentic workflows with state and determinism.\n",
      "\n",
      "### Key Features of Agno\n",
      "- **Model Agnostic**: Supports over 23+ model providers without lock-in.\n",
      "- **Highly Performant**: Fast agent instantiation (~3μs) and low memory usage (~6.5KiB).\n",
      "- **Reasoning Support**: Includes multiple approaches like reasoning models, tools, or chain-of-thought methods.\n",
      "- **Natively Multi-Modal**: Accepts text, image, audio, and video as input and output.\n",
      "- **Multi-Agent Architecture**: Industry-leading support for multi-agent collaboration (Agent Teams).\n",
      "- **Built-In Tools**:\n",
      "  - Search using 20+ vector databases.\n",
      "  - Memory and session storage.\n",
      "  - Structured outputs.\n",
      "  - Pre-built FastAPI routes for deployment.\n",
      "- **Monitoring & Debugging**: Real-time monitoring via app.agno.com and built-in debugging tools.\n",
      "- **Agent Playground**: A frontend UI for interacting with agents and teams locally.\n",
      "\n",
      "Agno enables the creation of complex autonomous systems while simplifying development through pre-built components and integrations. Learn more at [Agno's documentation](https://docs.agno.com/introduction).\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "419b8e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> HTTP status error while crawling <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://docs.agno.com/:</span> Redirect response <span style=\"color: #008000; text-decoration-color: #008000\">'308 Permanent Redirect'</span> for   \n",
       "         url <span style=\"color: #008000; text-decoration-color: #008000\">'https://docs.agno.com/'</span>                                                                              \n",
       "         Redirect location: <span style=\"color: #008000; text-decoration-color: #008000\">'/introduction'</span>                                                                        \n",
       "         For more information check: <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/308</span>                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mWARNING \u001b[0m HTTP status error while crawling \u001b[4;94mhttps://docs.agno.com/:\u001b[0m Redirect response \u001b[32m'308 Permanent Redirect'\u001b[0m for   \n",
       "         url \u001b[32m'https://docs.agno.com/'\u001b[0m                                                                              \n",
       "         Redirect location: \u001b[32m'/introduction'\u001b[0m                                                                        \n",
       "         For more information check: \u001b[4;94mhttps://developer.mozilla.org/en-US/docs/Web/HTTP/Status/308\u001b[0m                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(content='Agno home page Search... Ask AI Discord Community agno-agi / agno agno-agi / agno Search... Navigation Introduction What is Agno? User Guide Examples Workspaces FAQs API reference Changelog Introduction What is Agno? Your first Agents Multi Agent Systems Agent Playground Monitoring & Debugging Community & Support Concepts Agents Teams Models Tools Reasoning Memory Knowledge Chunking Vector DBs Storage Embeddings Evals Workflows Applications Other Agent UI Agent API Observability How to Install & Setup Contributing to Agno Migrate from Phidata to Agno Introduction What is Agno? Copy page Agno is a full-stack framework for building Multi-Agent Systems with memory, knowledge and reasoning. Engineers and researchers use Agno to build the 5 levels of Agentic Systems: Level 1: Agents with tools and instructions ( example ). Level 2: Agents with knowledge and storage ( example ). Level 3: Agents with memory and reasoning ( example ). Level 4: Agent Teams that can reason and collaborate ( example ). Level 5: Agentic Workflows with state and determinism ( example ). Example: Level 1 Reasoning Agent that uses the YFinance API to answer questions: Reasoning Finance Agent from agno.agent import Agent from agno.models.anthropic import Claude from agno.tools.reasoning import ReasoningTools from agno.tools.yfinance import YFinanceTools reasoning_agent = Agent( model =Claude( id = \"claude-sonnet-4-20250514\" ), tools =[ ReasoningTools( add_instructions = True ), YFinanceTools( stock_price = True , analyst_recommendations = True , company_info = True , company_news = True ), ], instructions = \"Use tables to display data.\" , markdown = True , ) Watch the reasoning finance agent in action \\u200b Getting Started If you’re new to Agno, learn how to build your first Agent , chat with it on the playground and monitor it on app.agno.com . Your first Agents Learn how to build Agents with Agno Agent Playground Chat with your Agents using a beautiful Agent UI Agent Monitoring Monitor your Agents on agno.com After that, dive deeper into the concepts below or explore the examples gallery to build real-world applications with Agno. \\u200b Why Agno? Agno will help you build best-in-class, highly-performant agentic systems, saving you hours of research and boilerplate. Here are some key features that set Agno apart: Model Agnostic : Agno provides a unified interface to 23+ model providers, no lock-in. Highly performant : Agents instantiate in ~3μs and use ~6.5Kib memory on average. Reasoning is a first class citizen : Reasoning improves reliability and is a must-have for complex autonomous agents. Agno supports 3 approaches to reasoning: Reasoning Models, ReasoningTools or our custom chain-of-thought approach. Natively Multi-Modal : Agno Agents are natively multi-modal, they accept text, image, audio and video as input and generate text, image, audio and video as output. Advanced Multi-Agent Architecture : Agno provides an industry leading multi-agent architecture ( Agent Teams ) with reasoning, memory, and shared context. Built-in Agentic Search : Agents can search for information at runtime using 20+ vector databases. Agno provides state-of-the-art Agentic RAG, fully async and highly performant. Built-in Memory & Session Storage : Agents come with built-in Storage & Memory drivers that give your Agents long-term memory and session storage. Structured Outputs : Agno Agents can return fully-typed responses using model provided structured outputs or json_mode . Pre-built FastAPI Routes : After building your Agents, serve them using pre-built FastAPI routes. 0 to production in minutes. Monitoring : Monitor agent sessions and performance in real-time on agno.com . \\u200b Dive deeper Agno is a battle-tested framework with a state of the art reasoning and multi-agent architecture, read the following guides to learn more: Agents Learn how to build lightning fast Agents. Teams Build autonomous multi-agent teams. Models Use any model, any provider, no lock-in. Tools 100s of tools to extend your Agents. Reasoning Make Agents “think” and “analyze”. Knowledge Give Agents domain-specific knowledge. Vector Databases Store and search your knowledge base. Storage Persist Agent session and state in a database. Memory Remember user details and session summaries. Embeddings Generate embeddings for your knowledge base. Workflows Deterministic, stateful, multi-agent workflows. Evals Evaluate, monitor and improve your Agents. Was this page helpful? Yes No Suggest edits Raise issue Your first Agents x github discord youtube website Powered by Mintlify On this page Getting Started Why Agno? Dive deeper Assistant Responses are generated using AI and may contain mistakes.', id='https://docs.agno.com/introduction_1', name='https://docs.agno.com/introduction', meta_data={'url': 'https://docs.agno.com/introduction', 'chunk': 1, 'chunk_size': 4687}, embedder=None, embedding=None, usage=None, reranking_score=None), Document(content='Agno home page Search... Ask AI Discord Community agno-agi / agno agno-agi / agno Search... Navigation Examples Examples Gallery User Guide Examples Workspaces FAQs API reference Changelog Examples Examples Getting Started Agents Teams Workflows Applications Streamlit Apps Evals Agent Concepts Reasoning Multimodal RAG User Control Flows Knowledge Memory Async Hybrid Search Storage Tools Vector Databases Context Embedders Agent State Observability Miscellaneous Models Anthropic AWS Bedrock AWS Bedrock Claude Azure AI Foundry Azure OpenAI Cerebras Cerebras OpenAI Cohere DeepInfra DeepSeek Fireworks Gemini Groq Hugging Face IBM LM Studio LiteLLM LiteLLM OpenAI Meta Mistral NVIDIA Ollama OpenAI Perplexity Together XAI Vercel Examples Examples Gallery Copy page Explore Agno’s example gallery showcasing everything from single-agent tasks to sophisticated multi-agent workflows. Welcome to Agno’s example gallery! Here you’ll discover examples showcasing everything from single-agent tasks to sophisticated multi-agent workflows . You can either: Run the examples individually Clone the entire Agno cookbook Have an interesting example to share? Please consider contributing to our growing collection. \\u200b Getting Started If you’re just getting started, follow the Getting Started guide for a step-by-step tutorial. The examples build on each other, introducing new concepts and capabilities progressively. \\u200b Use Cases Build real-world applications with Agno. Simple Agents Simple agents for web scraping, data processing, financial analysis, etc. Advanced Workflows Advanced workflows for creating blog posts, investment reports, etc. Full stack Applications Full stack applications like the LLM OS that come with a UI, database etc. \\u200b Agent Concepts Explore Agent concepts with detailed examples. Multimodal Learn how to use multimodal Agents RAG Learn how to use Agentic RAG Knowledge Add domain-specific knowledge to your Agents Async Run Agents asynchronously Hybrid search Combine semantic and keyword search Memory Let Agents remember past conversations Tools Extend your Agents with 100s or tools Storage Store Agents sessions in a database Vector Databases Store Knowledge in Vector Databases Embedders Convert text to embeddings to store in VectorDbs \\u200b Models Explore different models with Agno. OpenAI Examples using OpenAI GPT models Ollama Examples using Ollama models locally Anthropic Examples using Anthropic models like Claude Cohere Examples using Cohere command models DeepSeek Examples using DeepSeek models Gemini Examples using Google Gemini models Groq Examples using Groq’s fast inference Mistral Examples using Mistral models Azure Examples using Azure OpenAI Fireworks Examples using Fireworks models AWS Examples using Amazon Bedrock Hugging Face Examples using Hugging Face models NVIDIA Examples using NVIDIA models Together Examples using Together AI models xAI Examples using xAI models Was this page helpful? Yes No Suggest edits Raise issue Introduction x github discord youtube website Powered by Mintlify On this page Getting Started Use Cases Agent Concepts Models Assistant Responses are generated using AI and may contain mistakes.', id='https://docs.agno.com/examples/introduction_1', name='https://docs.agno.com/introduction', meta_data={'url': 'https://docs.agno.com/examples/introduction', 'chunk': 1, 'chunk_size': 3172}, embedder=None, embedding=None, usage=None, reranking_score=None), Document(content='Agno home page Search... Ask AI Discord Community agno-agi / agno agno-agi / agno Search... Navigation Workspaces Standardized Codebases for Agentic Systems User Guide Examples Workspaces FAQs API reference Changelog Workspaces Overview Agent App Agent API Workspace Management Introduction Development Application Production Application Install & Setup Add Python Libraries Add Secrets Environment variables Database Tables CI/CD Custom Domain & HTTPS SSH Access Workspace Settings Create Git Repo Add New Users Format & Validate Workspaces Standardized Codebases for Agentic Systems Copy page When building an Agentic System, you’ll need an API to serve your Agents, a database to store session and vector data and an admin interface for testing and evaluation. You’ll also need cron jobs, alerting and data pipelines for ingestion and cleaning. This system would generally take a few months to build, we’re open-sourcing it for the community for free. \\u200b What are Workspaces? Workspaces are standardized codebases for production Agentic Systems. They contain: A RestAPI (FastAPI) for serving Agents, Teams and Workflows. A streamlit application for testing — think of this as an admin interface. A postgres database for session and vector storage. Workspaces are setup to run locally using docker and be easily deployed to AWS. They’re a fantastic starting point and exactly what we use for our customers. You’ll definitely need to customize them to fit your specific needs, but they’ll get you started much faster. They contain years of learnings, available for free for the open-source community. \\u200b Here’s how they work Create your codebase using: ag ws create Run locally using docker: ag ws up Run on AWS: ag ws up prd:aws We recommend starting with the agent-app template and taking it from there. Agent App An Agentic System built with FastAPI, Streamlit and a Postgres database. Agent Api An Agent API built with FastAPI and Postgres. \\u200b How we build Agentic Systems When building Agents, we experiment locally till we achieve 6/10 quality. This helps us see quick results and get a rough idea of how our solution should look like in production. Then, we start moving to a production environment and iterate from there. Here’s how we build production systems: Serve Agents, Teams and Workflows via a REST API (FastAPI). Use a streamlit application for debugging and testing. This streamlit app is generally used as an admin interface for the agentic system and shows all sorts of data. Monitor, evaluate and improve the implementation until we reach 9/10 quality. In parallel, we start integrating our front-end with the REST API above. Having built 100s of such systems, we have a standard set of codebases we use and we call them Workspaces . They help us manage our Agentic System as code. We strongly believe that your AI applications should run securely inside your VPC. We fully support BYOC (Bring Your Own Cloud) and encourage you to use your own cloud account. Was this page helpful? Yes No Suggest edits Raise issue Running locally x github discord youtube website Powered by Mintlify On this page What are Workspaces? Here’s how they work How we build Agentic Systems Assistant Responses are generated using AI and may contain mistakes.', id='https://docs.agno.com/workspaces/introduction_1', name='https://docs.agno.com/introduction', meta_data={'url': 'https://docs.agno.com/workspaces/introduction', 'chunk': 1, 'chunk_size': 3255}, embedder=None, embedding=None, usage=None, reranking_score=None), Document(content='Agno home page Search... Ask AI Discord Community agno-agi / agno agno-agi / agno Search... Navigation FAQs Setting Environment Variables User Guide Examples Workspaces FAQs API reference Changelog FAQs Environment Variables Setup TPM rate limiting Command line authentication Connecting to Tableplus Docker Connection Error OpenAI Key Request While Using Other Models Structured outputs When to use a Workflow vs a Team in Agno Memory V2 FAQs Setting Environment Variables Copy page To configure your environment for applications, you may need to set environment variables. This guide provides instructions for setting environment variables in both macOS (Shell) and Windows (PowerShell and Windows Command Prompt). \\u200b macOS \\u200b Setting Environment Variables in Shell \\u200b Temporary Environment Variables These environment variables will only be available in the current shell session. export VARIABLE_NAME = \"value\" To display the environment variable: echo $VARIABLE_NAME \\u200b Permanent Environment Variables To make environment variables persist across sessions, add them to your shell configuration file (e.g., .bashrc , .bash_profile , .zshrc ). For Zsh: echo \\'export VARIABLE_NAME=\"value\"\\' >> ~/.zshrc source ~/.zshrc To display the environment variable: echo $VARIABLE_NAME \\u200b Windows \\u200b Setting Environment Variables in PowerShell \\u200b Temporary Environment Variables These environment variables will only be available in the current PowerShell session. $env:VARIABLE_NAME = \"value\" To display the environment variable: echo $env:VARIABLE_NAME \\u200b Permanent Environment Variables To make environment variables persist across sessions, add them to your PowerShell profile script (e.g., Microsoft.PowerShell_profile.ps1 ). notepad $PROFILE Add the following line to the profile script: $env:VARIABLE_NAME = \"value\" Save and close the file, then reload the profile: . $PROFILE To display the environment variable: echo $env:VARIABLE_NAME \\u200b Setting Environment Variables in Windows Command Prompt \\u200b Temporary Environment Variables These environment variables will only be available in the current Command Prompt session. set VARIABLE_NAME=value To display the environment variable: echo %VARIABLE_NAME% \\u200b Permanent Environment Variables To make environment variables persist across sessions, you can use the setx command: setx VARIABLE_NAME \"value\" Note: After setting an environment variable using setx , you need to restart the Command Prompt or any applications that need to read the new environment variable. To display the environment variable in a new Command Prompt session: echo %VARIABLE_NAME% By following these steps, you can effectively set and display environment variables in macOS Shell, Windows Command Prompt, and PowerShell. This will ensure your environment is properly configured for your applications. Was this page helpful? Yes No Suggest edits Raise issue TPM rate limiting x github discord youtube website Powered by Mintlify On this page macOS Setting Environment Variables in Shell Temporary Environment Variables Permanent Environment Variables Windows Setting Environment Variables in PowerShell Temporary Environment Variables Permanent Environment Variables Setting Environment Variables in Windows Command Prompt Temporary Environment Variables Permanent Environment Variables Assistant Responses are generated using AI and may contain mistakes.', id='https://docs.agno.com/faq/environment-variables_1', name='https://docs.agno.com/introduction', meta_data={'url': 'https://docs.agno.com/faq/environment-variables', 'chunk': 1, 'chunk_size': 3365}, embedder=None, embedding=None, usage=None, reranking_score=None), Document(content='Agno home page Search... Ask AI Discord Community agno-agi / agno agno-agi / agno Search... Navigation Agents Agent User Guide Examples Workspaces FAQs API reference Changelog Reference Agents Agent Session Teams Workflows Models Knowledge Vector Databases Embedders Memory Storage Rerankers Chunking Document Reader Agents Agent Copy page \\u200b Parameters Parameter Type Default Description model Optional[Model] None Model to use for this Agent name Optional[str] None Agent name agent_id Optional[str] None Agent UUID (autogenerated if not set) agent_data Optional[Dict[str, Any]] None Metadata associated with this agent introduction Optional[str] None Agent introduction. This is added to the chat history when a run is started. user_id Optional[str] None ID of the user interacting with this agent user_data Optional[Dict[str, Any]] None Metadata associated with the user interacting with this agent session_id Optional[str] None Session UUID (autogenerated if not set) session_name Optional[str] None Session name session_state Optional[Dict[str, Any]] None Session state (stored in the database to persist across runs) context Optional[Dict[str, Any]] None Context available for tools and prompt functions add_context bool False If True, add the context to the user prompt resolve_context bool True If True, resolve the context (i.e. call any functions in the context) before running the agent memory Optional[Memory] None Agent Memory add_history_to_messages bool False Add chat history to the messages sent to the Model num_history_runs int 3 Number of historical runs to include in the messages. search_previous_sessions_history bool False Set this to True to allow searching through previous sessions. num_history_sessions int 2 Specify the number of past sessions to include in the search. It\\'s advisable to keep this number to 2 or 3 for now, as a larger number might fill up the context length of the model, potentially leading to performance issues. knowledge Optional[AgentKnowledge] None Agent Knowledge knowledge_filters Optional[Dict[str, Any]] None Knowledge filters to apply to the knowledge base enable_agentic_knowledge_filters bool False Enable agentic knowledge filters add_references bool False Enable RAG by adding references from AgentKnowledge to the user prompt retriever Optional[Callable[..., Optional[List[Dict]]]] None Function to get references to add to the user_message references_format Literal[\"json\", \"yaml\"] \"json\" Format of the references storage Optional[AgentStorage] None Agent Storage extra_data Optional[Dict[str, Any]] None Extra data stored with this agent tools Optional[List[Union[Toolkit, Callable, Function]]] None A list of tools provided to the Model show_tool_calls bool False Show tool calls in Agent response tool_call_limit Optional[int] None Maximum number of tool calls allowed for a single run tool_choice Optional[Union[str, Dict[str, Any]]] None Controls which (if any) tool is called by the model reasoning bool False Enable reasoning by working through the problem step by step reasoning_model Optional[Model] None Model to use for reasoning reasoning_agent Optional[Agent] None Agent to use for reasoning reasoning_min_steps int 1 Minimum number of reasoning steps reasoning_max_steps int 10 Maximum number of reasoning steps read_chat_history bool False Add a tool that allows the Model to read the chat history search_knowledge bool True Add a tool that allows the Model to search the knowledge base update_knowledge bool False Add a tool that allows the Model to update the knowledge base read_tool_call_history bool False Add a tool that allows the Model to get the tool call history system_message Optional[Union[str, Callable, Message]] None Provide the system message as a string or function. This overrides description , goal , instructions , etc. and sends the provided system message as-is. system_message_role str \"system\" Role for the system message create_default_system_message bool True If True, create a default system message using agent settings description Optional[str] None A description of the Agent that is added to the start of the system message goal Optional[str] None The goal of this task success_criteria Optional[str] None Success criteria for the agent instructions Optional[Union[str, List[str], Callable]] None List of instructions for the agent expected_output Optional[str] None Provide the expected output from the Agent additional_context Optional[str] None Additional context added to the end of the system message markdown bool False If markdown=true, add instructions to format the output using markdown add_name_to_instructions bool False If True, add the agent name to the instructions add_datetime_to_instructions bool False If True, add the current datetime to the instructions add_state_in_messages bool False If True, add the session state variables in messages add_messages Optional[List[Union[Dict, Message]]] None A list of extra messages added after the system message user_message', id='https://docs.agno.com/reference/agents/agent_1', name='https://docs.agno.com/introduction', meta_data={'url': 'https://docs.agno.com/reference/agents/agent', 'chunk': 1, 'chunk_size': 4995}, embedder=None, embedding=None, usage=None, reranking_score=None), Document(content=' Optional[Union[List, Dict, str, Callable, Message]] None Provide the user message user_message_role str \"user\" Role for the user message create_default_user_message bool True If True, create a default user message retries int 0 Number of retries to attempt delay_between_retries int 1 Delay between retries exponential_backoff bool False If True, the delay between retries is doubled each time response_model Optional[Type[BaseModel]] None Provide a response model to get the response as a Pydantic model parse_response bool True If True, the response is converted into the response_model use_json_mode bool False If response_model is set, sets the response \"mode\" of the model, i.e. if the model should explicitly respond with a JSON object instead of a Pydantic model save_response_to_file Optional[str] None Save the response to a file stream Optional[bool] None Stream the response from the Agent stream_intermediate_steps bool False Stream the intermediate steps from the Agent team Optional[List[Agent]] None The team of agents that this agent can transfer tasks to team_data Optional[Dict[str, Any]] None Data shared between team members role Optional[str] None If this Agent is part of a team, this is the role of the agent respond_directly bool False If True, member agent responds directly to user add_transfer_instructions bool True Add instructions for transferring tasks to team members team_response_separator str \"\\\\n\" Separator between responses from the team debug_mode bool False Enable debug logs monitoring bool False Log Agent information to agno.com for monitoring telemetry bool True Log minimal telemetry for analytics \\u200b Functions \\u200b print_response Run the agent and print the response. Parameters: message (Optional[Union[List, Dict, str, Message]]): The message to send to the agent session_id (Optional[str]): Session ID to use user_id (Optional[str]): User ID to use messages (Optional[List[Union[Dict, Message]]]): List of additional messages to use audio (Optional[Sequence[Audio]]): Audio files to include images (Optional[Sequence[Image]]): Image files to include videos (Optional[Sequence[Video]]): Video files to include files (Optional[Sequence[File]]): Files to include stream (Optional[bool]): Whether to stream the response stream_intermediate_steps (bool): Whether to stream intermediate steps markdown (bool): Whether to format output as markdown show_message (bool): Whether to show the message show_reasoning (bool): Whether to show reasoning show_full_reasoning (bool): Whether to show full reasoning console (Optional[Any]): Console to use for output knowledge_filters (Optional[Dict[str, Any]]): Knowledge filters to apply \\u200b run Run the agent. Parameters: message (Optional[Union[str, List, Dict, Message]]): The message to send to the agent stream (Optional[bool]): Whether to stream the response user_id (Optional[str]): User ID to use session_id (Optional[str]): Session ID to use audio (Optional[Sequence[Audio]]): Audio files to include images (Optional[Sequence[Image]]): Image files to include videos (Optional[Sequence[Video]]): Video files to include files (Optional[Sequence[File]]): Files to include messages (Optional[Sequence[Union[Dict, Message]]]): List of additional messages to use stream_intermediate_steps (Optional[bool]): Whether to stream intermediate steps retries (Optional[int]): Number of retries to attempt knowledge_filters (Optional[Dict[str, Any]]): Knowledge filters to apply Returns: Union[RunResponse, Iterator[RunResponse]] : Either a RunResponse or an iterator of RunResponses, depending on the stream parameter \\u200b aprint_response Run the agent and print the response asynchronously. Parameters: message (Optional[Union[List, Dict, str, Message]]): The message to send to the agent session_id (Optional[str]): Session ID to use user_id (Optional[str]): User ID to use messages (Optional[List[Union[Dict, Message]]]): List of additional messages to use audio (Optional[Sequence[Audio]]): Audio files to include images (Optional[Sequence[Image]]): Image files to include videos (Optional[Sequence[Video]]): Video files to include files (Optional[Sequence[File]]): Files to include stream (Optional[bool]): Whether to stream the response stream_intermediate_steps (bool): Whether to stream intermediate steps markdown (bool): Whether to format output as markdown show_message (bool): Whether to show the message show_reasoning (bool): Whether to show reasoning show_full_reasoning (bool): Whether to show full reasoning console (Optional[Any]): Console to use for output knowledge_filters (Optional[Dict[str, Any]]): Knowledge filters to apply \\u200b arun Run the agent asynchronously. Parameters: message (Optional[Union[str, List, Dict, Message]]): The message to send to the agent stream (Optional[bool]): Whether to stream the response user_id (Optional[str]): User ID to use session_id (Optional[str]): Session ID to use audio (Optional[Sequence[Audio]]): Audio files to include images (Optional[Sequence[Image]]): Image', id='https://docs.agno.com/reference/agents/agent_2', name='https://docs.agno.com/introduction', meta_data={'url': 'https://docs.agno.com/reference/agents/agent', 'chunk': 2, 'chunk_size': 4995}, embedder=None, embedding=None, usage=None, reranking_score=None), Document(content=' files to include videos (Optional[Sequence[Video]]): Video files to include files (Optional[Sequence[File]]): Files to include messages (Optional[Sequence[Union[Dict, Message]]]): List of additional messages to use stream_intermediate_steps (Optional[bool]): Whether to stream intermediate steps retries (Optional[int]): Number of retries to attempt knowledge_filters (Optional[Dict[str, Any]]): Knowledge filters to apply Returns: Union[RunResponse, AsyncIterator[RunResponse]] : Either a RunResponse or an iterator of RunResponses, depending on the stream parameter \\u200b continue_run Continue a run. Parameters: run_response (Optional[RunResponse]): The run response to continue run_id (Optional[str]): The run ID to continue updated_tools (Optional[List[ToolExecution]]): Updated tools to use, required if the run is resumed using run_id stream (Optional[bool]): Whether to stream the response stream_intermediate_steps (Optional[bool]): Whether to stream intermediate steps user_id (Optional[str]): User ID to use session_id (Optional[str]): Session ID to use retries (Optional[int]): Number of retries to attempt knowledge_filters (Optional[Dict[str, Any]]): Knowledge filters to apply Returns: Union[RunResponse, Iterator[RunResponse]] : Either a RunResponse or an iterator of RunResponses, depending on the stream parameter \\u200b acontinue_run Continue a run asynchronously. Parameters: run_response (Optional[RunResponse]): The run response to continue run_id (Optional[str]): The run ID to continue updated_tools (Optional[List[ToolExecution]]): Updated tools to use, required if the run is resumed using run_id stream (Optional[bool]): Whether to stream the response stream_intermediate_steps (Optional[bool]): Whether to stream intermediate steps user_id (Optional[str]): User ID to use session_id (Optional[str]): Session ID to use retries (Optional[int]): Number of retries to attempt knowledge_filters (Optional[Dict[str, Any]]): Knowledge filters to apply Returns: Union[RunResponse, AsyncIterator[RunResponse]] : Either a RunResponse or an iterator of RunResponses, depending on the stream parameter \\u200b get_session_summary Get the session summary for the given session ID and user ID. Parameters: session_id (Optional[str]): Session ID to use (if not provided, the current session is used) user_id (Optional[str]): User ID to use (if not provided, the current user is used) Returns: Optional[SessionSummary] : The session summary \\u200b get_user_memories Get the user memories for the given user ID. Parameters: user_id (Optional[str]): User ID to use (if not provided, the current user is used) Returns: Optional[List[UserMemory]] : The user memories Was this page helpful? Yes No Suggest edits Raise issue Session x github discord youtube website Powered by Mintlify On this page Parameters Functions print_response run aprint_response arun continue_run acontinue_run get_session_summary get_user_memories Assistant Responses are generated using AI and may contain mistakes.', id='https://docs.agno.com/reference/agents/agent_3', name='https://docs.agno.com/introduction', meta_data={'url': 'https://docs.agno.com/reference/agents/agent', 'chunk': 3, 'chunk_size': 2980}, embedder=None, embedding=None, usage=None, reranking_score=None), Document(content='Agno home page Search... Ask AI Discord Community agno-agi / agno agno-agi / agno Search... Navigation Changelog Product updates User Guide Examples Workspaces FAQs API reference Changelog Changelog Product updates Changelog Product updates Copy page \\u200b 2025-05-30 v1.5.6 \\u200b New Features Team Evals : All types of Evaluations now support Teams! \\u200b Improvements: Async Workflows : Added arun support for Workflows, so they can now be used with async Python. Parallel Memory Updates : Made speed improvements when user memories and session summaries are generated. Reimplement tool_call_limit : Revamp of tool_call_limit to make it work across a whole agent run. Gemini / OpenAI Structure Response: Improved Gemini and OpenAI Structured Response support. Dict types can now be used when defining structured responses. \\u200b Bug Fixes: Mistral Structured Outputs with Tools : Fixed an issue preventing Mistral model use with structured output and tools. Images In Run Without Prompt : Fixed issues related to images being ignored if there wasn’t a prompt provided on run . Pgvector Upsert Fix: Fixed Pgvector upsert not copying metadata properly. Handle AgnoInstrumentor failing with OpenAIResponses: PR merged in Arize’s openinference repo: https://github.com/Arize-ai/openinference/pull/1701 . Pinecone Filters: Enabled filters for pinecone vector db. Combined KB Async: Add missing async method to Combined KB. Team Session State Fix : team_session_state is now correctly propagated and shared between all members and sub-teams of a team. Gemini type fix for integers: Pydantic models with Dict[str, int] fields (and other Dict types) were failing when used as response_schema for both OpenAI and Gemini models due to schema format incompatibilities. Session Name : session_name is now available after a run. Handle UUIDs while serialization in RedisStorage: Fixed error object of type UUID is not JSON serializable. \\u200b Updates: For managing team_session_state , you now have to set team_session_state on the Team instead of session_state . \\u200b 2025-05-27 v1.5.5 \\u200b New Features: Claude File Upload: We can now upload a file to Anthropic directly and then use it as an input to an agent. Claude 4 Code Execution Tool: Updated Claude to execute Python code in a secure, sandboxed environment. **Prompt caching with Anthropic Models: ** Allowed resuming from specific prefixes in your prompts. This approach significantly reduces processing time and costs for repetitive tasks or prompts with consistent elements. Vercel v0 Model: Added support for new Vercel v0 models and cookbook examples. Qdrant Hybrid Search support Markdown Knowledge Base : Added native support for Markdown-based knowledge bases. AI/ML API platform integration: Introduced integration with AI/ML API , a platform providing AI/ML models. AI/ML API provides 300+ AI models including Deepseek, Gemini, ChatGPT. The models run at enterprise-grade rate limits and uptimes. Update Pydantic and dataclass in function handling: Added support for Pydantic and dataclass objects as input to a function. See here for an example. \\u200b Improvements: Timeout handling for API calls in ExaTools class: Timeout functionality to Exa API calls to prevent indefinite hanging of search operations. The implementation uses Python’s concurrent.futures module to enforce timeouts on all Exa API operations (search, get contents, find similar, and answer generation). This change addresses the issue where Exa search functions would hang indefinitely, causing potential service disruptions and resource leaks. Fetch messages from last N sessions: A tool for the agent, something like get_previous_session_messages(number_of_sessions: int) that returns a list of messages that the agent can analyse Switch on with search_previous_sessions_history Redis Expiration : Added expire key to set TTL on Redis keys. Add Anthropic Cache Write to Agent Session Metrics: Added cache_creation_input_tokens to agent session metrics, to allow for tracking Anthropic cache write statistics \\u200b Bug Fixes: Huggingface Embedder Updates: Huggingface has changed some things on their API and they’ve deprecated .post on their InferenceClient() - https://discuss.huggingface.co/t/getting-error-attributeerror-inferenceclient-object-has-no-attribute-post/156682 We can also no longer use id: str = \"jinaai/jina-embeddings-v2-base-code\" as default, because these models are no longer provided by the HF Inference API . Changed the default to id: str = \"intfloat/multilingual-e5-large\" Add role_map for OpenAIChat : This allows certain models that don’t adhere to OpenAI’s role mapping to be used vir OpenAILike . Use Content Hash as ID in Upsert in Pgvector: Use reproducible content_hash in upsert as ID. Insert in Vector DB passes only last chunk meta_data: Insert in vector db passes only last chunk meta_data. issue link- https://discord.com/channels/965734768803192842/1219054452221153463/1376631140047130649 Remove Argument Sanitization: Replaced with a safer way to do this that', id='https://docs.agno.com/changelog/overview_1', name='https://docs.agno.com/introduction', meta_data={'url': 'https://docs.agno.com/changelog/overview', 'chunk': 1, 'chunk_size': 4996}, embedder=None, embedding=None, usage=None, reranking_score=None), Document(content=' won’t break arguments that shouldn’t be sanitized Handle async tools when running async agents on playground: Fixed a regression where using Agents with async tools (e.g. MCP tools) was breaking in the Playground. \\u200b 2025-05-23 v1.5.4 \\u200b New Features: User Control Flows : This is the beta release of Agno’s Human-in-the-loop flows and tools. We now allow agent runs to be paused awaiting completion of certain user requirements before the agent can continue. This also adds the agent.continue_run and agent.acontinue_run functions. The control flows that are available: User confirmation flow → Decorate a function with @tool(requires_confirmation=True) and the agent will expect user confirmation before executing the tool. User input required → Decorate a function with @tool(requires_user_input=True) to have the agent stop and ask for user input before continuing. External tool execution → Decorate a function with @tool(external_execution=True) to indicate that you will execute this function outside of the agent context. Dynamic user input → Add UserControlFlowTools() to an agent to give the agent the ability to dynamically stop the flow and ask for user input where required. See a host of examples here . Mem0 Toolkit : Added a toolkit for managing memories in Mem0. Firecrawl Search : Added support for Firecrawl web search in FirecrawlTools . \\u200b Bug Fixes: Firecrawl Tools and Reader : Fixed parameter parsing for the Firecrawl reader and tools. Include/Exclude on all Tools : Ensure all toolkits support include_tools and exclude_tools . \\u200b 2025-05-21 v1.5.3 \\u200b Improvements: Improved Accuracy Evals: Updated the way accuracy evals works for more accurate agent-based evaluation. \\u200b Bug Fixes: MCP Client Timeout: Client timeouts now work correctly and use the timeout set on parameters. \\u200b 2025-05-20 v1.5.2 \\u200b New Features: Agno Apps (Beta) : Introducing Agno Apps, convenience functions to assist with building production-ready applications. The first supported apps are: FastAPIApp → A really simple FastAPI server that provides access to your agent or team . WhatsappAPIApp → An app that implements the Whatsapp protocol allowing you to have an Agno agent running on Whatsapp. Supports image / audio / video input and can generate images as responses. Supports reasoning. Couchbase Vector DB Support : Added support for Couchbase as a vector DB for knowledge bases. Knowledge Filters Update for Teams: Filters (manual + agentic) can now be used with Teams. Azure Cosmos DB for MongoDB (vCore) vector db support: In the MongoDB vector db class add support for cosmosdb mongo vcore support by enabling cosmos_compatibility=True Google Big Query Tools : Added Toolkit for Google BigQuery support. Async Support for s3 Readers: Add async support for pdf and text s3 readers. stop_after_tool_call and show_result for Toolkits: Now the base Toolkit class has stop_after_tool_call_tools and show_result_tools similar to the @tool decorator. \\u200b 2025-05-16 v1.5.1 \\u200b New Features: Nebius Model Provider : Added Nebius as a model provider. Extended Filters Support on Vector DBs : Added filtering support for other vector DBs. pgvector Milvus Weaviate Chroma \\u200b Improvements: Redis SSL : Added the ssl parameter to Redis storage. \\u200b 2025-05-13 v1.5.0 \\u200b New Features: Azure OpenAI Tools : Added image generation via Dall-E via Azure AI Foundry. OpenTelemetry Instrumentation: We have contributed to the OpenInference project and added an auto-instrumentor for Agno agents. This adds tracing instrumentation for Agno Agents for any OpenTelemetry-compatible observability provider. These include Arize, Langfuse and Langsmith. Examples added to illustrate how to use each one ( here ). Evals Updates : Added logic to run accuracy evaluations with pre-generated answers and minor improvements for all evals classes. Hybrid Search and Reranker for Milvus Vector DB: Added support for hybrid_search on Milvus. MCP with Streamable-HTTP: Now supporting the streamable-HTTP transport for MCP servers. \\u200b Improvements: Knowledge Filters Cookbook: Instead of storing the sample data locally, we now pull it from s3 at runtime to keep the forking of the repo as light as possible. \\u200b Bug Fixes: Team Model State: Fixed issues related to state being shared between models on teams. Concurrent Agent Runs : Fixed certain race-conditions related to running agents concurrently. \\u200b Breaking changes: Evals Refactoring: Our performance evaluation class has been renamed from PerfEval to PerformanceEval Our accuracy evaluation class has new required fields: agent , prompt and expected_answer Concurrent Agent Runs: We removed duplicate information from some events during streaming ( stream=True ). Individual events will have more relevant data now. \\u200b 2025-05-10 v1.4.6 \\u200b New Features: Cerebras Model Provider : Added Cerebras as a model provider. Claude Web Search : Added support for Claude’s new web search tool . Knowledge Base Metadata Filtering (Beta) : Added support for filtering documents by metadata Two Ways', id='https://docs.agno.com/changelog/overview_2', name='https://docs.agno.com/introduction', meta_data={'url': 'https://docs.agno.com/changelog/overview', 'chunk': 2, 'chunk_size': 5000}, embedder=None, embedding=None, usage=None, reranking_score=None), Document(content=' to Apply Filters : Explicit Filtering : Pass filters directly to Agent or during run/query # Option 1: Filters on Agent initialization agent = Agent( knowledge =knowledge_base, knowledge_filters ={ \"filter_1\" : \"abc\" } ) # Option 2: Filters on run execution agent.run( \"Tell me about...\" , knowledge_filters ={ \"filter_1\" : \"abc\" }) See docs here Agentic Filtering : Agent automatically detects and applies filters from user queries # Enable automatic filter detection agent = Agent( knowledge =knowledge_base, enable_agentic_knowledge_filters = True ) # Agent extracts filters from query agent.run( \"Tell me about John Doe\\'s experience...\" ) See docs here Two approaches for adding metadata to documents: During Knowledge Base Initialization : knowledge_base = PDFKnowledgeBase( path =[ { \"path\" : \"file_1.pdf\" , \"metadata\" : { \"user_id\" : \"abc\" } }, { \"path\" : \"file_2.pdf\" , \"metadata\" : { \"user_id\" : \"xyz\" } } ]) During Individual Document Loading: knowledge_base.load_document( path = \"file.pdf\" , metadata ={ \"user_id\" : \"abc\" } ) Compatibility Knowledge Base Types : PDF , Text , DOCX , JSON , and PDF_URL Vector Databases : Qdrant , LanceDB , and MongoDB \\u200b Improvements: User and Session ID in Tools : Added current_user_id and current_session_id as default variables in session_data for Agent and Team . \\u200b Bug Fixes: Knowledge Base ID Clashes : Knowledge files with overlapping names (e.g., abc.-.xyz.pdf and abc.-.def.pdf ) were being incorrectly identified due to the readers using formatted names as unique id which were getting uniqueness conflict. Introduced a unique ID for each document in all the readers using uuidv4() to ensure strict identification and prevent conflicts. \\u200b 2025-05-06 v1.4.5 \\u200b New Features: Embedder Support via AWS Bedrock : AwsBedrockEmbedder has been added with a default embedding model of cohere.embed-multilingual-v3 . Gemini Video Generation Tool : Added video generation capabilities to GeminiTools . \\u200b Improvements: Apify Revamp : Complete revamp of ApifyTools to make it completely compatible with Apify actors. \\u200b Bug Fixes: Tools with Optional Parameters on Llama API : Fixed edge cases with functions. \\u200b 2025-05-03 v1.4.4 \\u200b New Features: OpenAI File Support: Added support for File attached to prompts for agents with OpenAIChat models. \\u200b Improvements: Llama API: Various improvements for Llama and LlamaOpenAI model classes including structured output and image input support Async Custom Retriever : The retriever parameter can now be an async function to be used with agent.arun and agent.aprint_response . Gemini Video URL Input : Added support for Video(url=...) for Gemini. \\u200b Bug Fixes: OpenAI Responses o3 / o4 Tools : Fixed broken tool use for advanced reasoning models on OpenAIResponses . MCP on CLI Support : Fixed support for MCPTools usage while calling agent.acli_app . \\u200b 2025-04-30 v1.4.3 \\u200b New Features: Llama API: Added native SDK and OpenAI-like model classes. \\u200b Improvements: Claude : Added support for AWS Session token for Claude. DynamoDB : Added support for AWS profile-based authentication. \\u200b Bug Fixes: Session Metrics : Fix for session metrics showing up as 0. HF Embedder fix : Fixed Hugging Face Embedder. \\u200b 2025-04-25 v1.4.2 \\u200b New Features: MCP SSE Support : Added support for connecting to SSE MCP Servers. Tool Hooks : You can now have a hook that is wrapped around all tool calls. This works for Toolkits and custom tools. See this example . Team Session State: You can now manage a single state dictionary across a team leader and team members inside tools given to the team leader/members. See this example . Cartesia Tool : Added support for Cartesia for text-to-speech capabilities. Gemini Image Tools: Added a tool that uses Gemini models to generate images. Groq Audio Tools : Added a tool that uses Groq models to translate, transcribe and generate audio. \\u200b Improvements: PubmedTools Expanded Results : Added expanded result sets for PubmedTools . Variety in Tool Results : Custom tools can now have any return type and it would be handled before being provided to the model. \\u200b Bug Fixes: Teams Shared Model Bug : Fixed issues where a single model is used across team members. This should reduce tool call failures in team execution. \\u200b 2025-04-23 v1.4.0 \\u200b New Features: Memory Generally Available : We have made improvements and adjustments to how Agentic user memory management works. This is now out of beta and generally available. See these examples and these docs for more info. OpenAI Tools : Added OpenAITools to enable text-to-speech and image generation through OpenAI’s APIs. Zep Tools : Added ZepTools and AsyncZepTools to manage memories for your Agent using zep-cloud \\u200b Improvements: Azure AI Foundry Reasoning : Added support for reasoning models via Azure AI Foundry. E.g. Deepseek-R1. Include/Exclude Tools : Added include_tools and exclude_tools for all toolkits. This allows for selective enabling / disabling of tools inside toolkits, which is especially useful for larger toolkits. \\u200b Bug', id='https://docs.agno.com/changelog/overview_3', name='https://docs.agno.com/introduction', meta_data={'url': 'https://docs.agno.com/changelog/overview', 'chunk': 3, 'chunk_size': 4997}, embedder=None, embedding=None, usage=None, reranking_score=None), Document(content=' Fixes: Gemini with Memory : Fixed issue with deepcopy when Gemini is used with Memory . \\u200b Breaking Changes: Memory: Agents will now by default use an improved Memory instead of the now deprecated AgentMemory . - agent.memory.messages → run.messages for run in agent.memory.runs (or agent.get_messages_for_session() ) - create_user_memories → enable_user_memories and is now set on the Agent/Team directly. - create_session_summary → enable_session_summaries and is now set on the Agent/Team directly. \\u200b 2025-04-21 v1.3.5 \\u200b Improvements: Further Async Vector DB Support : Support added for: Clickhouse ChromaDB Cassandra PineconeDB Pgvector Reasoning on Agno Platform : Added extensive support for reasoning on the Agno Platform. Go see your favourite reasoning agents in action! Changes from SDK send proper events in different types of reasoning and populate the reasoning_content on RunResponse for stream/non-stream , async/non-async unified json structure for all types of reasoning in Reasoning events Google Caching Support : Added support for caching files and sending the cached content to Gemini. \\u200b Bug Fixes Firecrawl Scrape : Fixed issues with non-serializable types for during Firecrawl execution. https://github.com/agno-agi/agno/issues/2883 \\u200b 2025-04-18 v1.3.4 \\u200b New Features: Web Browser Tool: Introduced a webbrowser tool for agents to interact with the web. Proxy Support: Added proxy parameter support to both URL and PDF tools for network customization. \\u200b Improvements: Session State: Added examples for managing session state in agents. AzureOpenAIEmbedder: Now considers client_params passed in the client_params argument for more flexible configuration. LiteLLM: Now uses built-in environment validation to simplify setup. Team Class: Added a mode attribute to team data serialization for enhanced team configuration. Insert/Upsert/Log Optimization: insert/upsert/log_info operations now trigger only when documents are present in the reader. Database Preference: Session state now prefers database-backed storage if available. Memory Management: Internal memory system updated for better session handling and resource efficiency. Module Exports: Init files that only import now explicitly export symbols using __all__ . \\u200b Bug Fixes: DynamoDB Storage: Fixed an issue with storage handling in DynamoDB-based setups. DeepSeek: Fixed a bug with API key validation logic. \\u200b 2025-04-17 v1.3.3 \\u200b Improvements: Gemini File Upload : Enabled direct use of uploaded files with Gemini. Metrics Update : Added audio, reasoning and cached token counts to metrics where available on models. Reasoning Updates : We now natively support Ollama and AzureOpenAI reasoning models. \\u200b Bug Fixes: PPrint Util Async : Added apprint_run_response to support async. Mistral Reasoning: Fixed issues with using a Mistral model for chain-of-thought reasoning. \\u200b 2025-04-16 v1.3.2 \\u200b New Features: Redis Memory DB : Added Redis as a storage provider for Memory . See here . \\u200b Improvements: Memory Updates : Various performance improvements made and convenience functions added: agent.get_session_summary() → Use to get the previous session summary from the agent. agent.get_user_memories() → Use to get the current user’s memories. You can also add additional instructions to the MemoryManager or SessionSummarizer . Confluence Bypass SSL Verification : If required, you can now skip SSL verification for Confluence connections. More Flexibility On Team Prompts : Added add_member_tools_to_system_message to remove the member tool names from the system message given to the team leader, which allows flexibility to make teams transfer functions work in more cases. \\u200b Bug Fixes: LiteLLM Streaming Tool Calls : Fixed issues with tool call streaming in LiteLLM. E2B Casing Issue : Fixed issues with parsed Python code that would make some values lowercase. Team Member IDs : Fixed edge-cases with team member IDs causing teams to break. \\u200b 2025-04-12 v1.3.0 \\u200b New Features: Memory Revamp (Beta) : This is a beta release of a complete revamp of Agno Memory. This includes a new Memory class that supports adding, updating and deleting user memories, as well as doing semantic search with a model. This also adds additional abilities to the agent to manage memories on your behalf. See the docs here . User ID and Session ID on Run : You can now pass user_id and session_id on agent.run() . This will ensure the agent is set up for the session belonging to the session_id and that only the memories of the current user is accessible to the agent. This allows you to build multi-user and multi-session applications with a single agent configuration. Redis Storage : Support added for Redis as a session storage provider. \\u200b 2025-04-11 v1.2.16 \\u200b Improvements: Teams Improvements : Multiple improvements to teams to make task forwarding to member agents more reliable and to make the team leader more conversational. Also added various examples of reasoning with teams. Knowledge on Teams : Added knowledge to Team to', id='https://docs.agno.com/changelog/overview_4', name='https://docs.agno.com/introduction', meta_data={'url': 'https://docs.agno.com/changelog/overview', 'chunk': 4, 'chunk_size': 4999}, embedder=None, embedding=None, usage=None, reranking_score=None), Document(content=' better align with the functionality on Agent . This comes with retriever to set a custom retriever and search_knowledge to enable Agentic RAG. \\u200b Bug Fixes: Gemini Grounding Chunks : Fixed error when Gemini Grounding was used in streaming. OpenAI Defaults in Structured Outputs : OpenAI does not allow defaults in structured outputs. To make our structured outputs as compatible as possible without adverse effects, we made updates to OpenAIResponses and OpenAIChat . \\u200b 2025-04-08 v1.2.14 \\u200b Improvements: Improved Github Tools : Added many more capabilities to GithubTools . Windows Scripts Support : Converted all the utility scripts to be Windows compatible. MongoDB VectorDB Async Support : MongoDB can now be used in async knowledge bases. \\u200b Bug Fixes: Gemini Tool Formatting : Fixed various cases where functions would not be parsed correctly when used with Gemini. ChromaDB Version Compatibility: Fix to ensure that ChromaDB and Agno are compatible with newer versions of ChromaDB. Team-Member Interactions : Fixed issue where if members respond with empty content the team would halt. This is now be resolved. Claude Empty Response: Fixed a case when the response did not include any content with tool calls resulting in an error from the Anthropic API \\u200b 2025-04-07 v1.2.12 \\u200b New Features: Timezone Identifier: Added a new timezone_identifier parameter in the Agent class to include the timezone alongside the current date in the instructions. Google Cloud JSON Storage : Added support for JSON-based session storage on Google Cloud. Reasoning Tools : Added ReasoningTools for an advanced reasoning scratchpad for agents. \\u200b Improvements: Async Vector DB and Knowledge Base Improvements : More knowledge bases have been updated for async-await support: - URLKnowledgeBase → Find some examples here . - FireCrawlKnowledgeBase → Find some examples here . - DocxKnowledgeBase → Find some examples here . \\u200b 2025-04-07 v1.2.11 \\u200b Bug Fixes: Fix for structured outputs : Fixed cases of structured outputs for reasoning. \\u200b 2025-04-07 v1.2.10 \\u200b 1.2.10 \\u200b New Features: Knowledge Tools : Added KnowledgeTools for thinking, searching and analysing documents in a knowledge base. \\u200b 2025-04-05 v1.2.9 \\u200b 1.2.9 \\u200b Improvements: Simpler MCP Interface : Added MultiMCPTools to support multiple server connections and simplified the interface to allow command to be passed. See these examples of how to use it. \\u200b 2025-04-04 v1.2.8 \\u200b 1.2.8 \\u200b Changelog \\u200b New Features: Toolkit Instructions : Extended Toolkit with instructions and add_instructions to enable you to specify additional instructions related to how a tool should be used. These instructions are then added to the model’s “system message” if add_instructions=True . \\u200b Bug Fixes: Teams transfer functions : Some tool definitions of teams failed for certain models. This has been fixed. \\u200b 2025-04-02 v1.2.7 \\u200b 1.2.7 \\u200b New Features: Gemini Image Generation : Added support for generating images straight from Gemini using the gemini-2.0-flash-exp-image-generation model. \\u200b Improvements: Vertex AI : Improved use of Vertex AI with Gemini Model class to closely follow the official Google specification Function Result Caching Improvement: We now have result caching on all Agno Toolkits and any custom functions using the @tool decorator. See the docs here . Async Vector DB and Knowledge Base Improvements : Various knowledge bases, readers and vector DBs now have async-await support, so it will be used in agent.arun and agent.aprint_response . This also means that knowledge_base.aload() is possible which should greatly increase loading speed in some cases. The following have been converted: Vector DBs: LanceDb → Here is a cookbook to illustrate how to use it. Milvus → Here is a cookbook to illustrate how to use it. Weaviate → Here is a cookbook to illustrate how to use it. Knowledge Bases: JSONKnowledgeBase → Here is a cookbook to illustrate how to use it. PDFKnowledgeBase → Here is a cookbook to illustrate how to use it. PDFUrlKnowledgeBase → Here is a cookbook to illustrate how to use it. CSVKnowledgeBase → Here is a cookbook to illustrate how to use it. CSVUrlKnowledgeBase → Here is a cookbook to illustrate how to use it. ArxivKnowledgeBase → Here is a cookbook to illustrate how to use it. WebsiteKnowledgeBase → Here is a cookbook to illustrate how to use it. YoutubeKnowledgeBase → Here is a cookbook to illustrate how to use it. TextKnowledgeBase → Here is a cookbook to illustrate how to use it. \\u200b Bug Fixes: Recursive Chunking Infinite Loop : Fixes an issue with RecursiveChunking getting stuck in an infinite loop for large documents. \\u200b 2025-03-28 v1.2.6 \\u200b 1.2.6 \\u200b Bug Fixes: Gemini Function call result fix : Fixed a bug with function call results failing formatting and added proper role mapping . Reasoning fix : Fixed an issue with default reasoning and improved logging for reasoning models . \\u200b 2025-03-27 v1.2.5 \\u200b 1.2.5 \\u200b New Features: E2B Tools: Added E2B Tools to run code in E2B Sandbox \\u200b Improvements: Teams Tools : Add', id='https://docs.agno.com/changelog/overview_5', name='https://docs.agno.com/introduction', meta_data={'url': 'https://docs.agno.com/changelog/overview', 'chunk': 5, 'chunk_size': 4998}, embedder=None, embedding=None, usage=None, reranking_score=None), Document(content=' tools and tool_call_limit to Team . This means the team leader itself can also have tools provided by the user, so it can act as an agent. Teams Instructions: Improved instructions around attached images, audio, videos, and files. This should increase success when attaching artifacts to prompts meant for member agents. MCP Include/Exclude Tools : Expanded MCPTools to allow you to specify tools to specifically include or exclude from all the available tools on an MCP server. This is very useful for limiting which tools the model has access to. Tool Decorator Async Support : The @tool() decorator now supports async functions, including async pre and post-hooks. \\u200b Bug Fixes: Default Chain-of-Thought Reasoning: Fixed issue where reasoning would not default to manual CoT if the provided reasoning model was not capable of reasoning. Teams non-markdown responses : Fixed issue with non-markdown responses in teams. Ollama tool choice: Removed tool_choice from Ollama usage as it is not supported. Worklow session retrieval from storage : Fixed entity_id mappings. \\u200b 2025-03-25 v1.2.4 \\u200b 1.2.4 \\u200b Improvements: Tool Choice on Teams : Made tool_choice configurable. \\u200b Bug Fixes: Sessions not created : Made issue where sessions would not be created in existing tables without a migration be more visible. Please read the docs on storage schema migrations . Todoist fixes : Fixed update_task on TodoistTools . \\u200b 2025-03-24 v1.2.3 \\u200b 1.2.3 \\u200b Improvements: Teams Error Handling: Improved the flow in cases where the model gets it wrong when forwarding tasks to members. \\u200b 2025-03-24 v1.2.2 \\u200b 1.2.2 \\u200b Bug Fixes: Teams Memory: Fixed issues related to memory not persisting correctly across multiple sessions. \\u200b 2025-03-24 v1.2.1 \\u200b 1.2.1 \\u200b Bug Fixes: Teams Markdown : Fixed issue with markdown in teams responses. \\u200b 2025-03-24 v1.2.0 \\u200b 1.2.0 \\u200b New Features: Financial Datasets Tools : Added tools for https://www.financialdatasets.ai/ . Docker Tools : Added tools to manage local docker environments. \\u200b Improvements: Teams Improvements: Reasoning enabled for the team. MCP Simplification: Simplified creation of MCPTools for connections to external MCP servers. See the updated docs . \\u200b Bug Fixes: Azure AI Factory: Fix for a broken import in Azure AI Factory. \\u200b 2025-03-23 v1.1.17 \\u200b 1.1.17 \\u200b Improvements: Better Debug Logs : Enhanced debug logs for better readability and clarity. \\u200b 2025-03-22 v1.1.16 \\u200b 1.1.16 \\u200b New Features: Async Qdrant VectorDB: Implemented async support for Qdrant VectorDB, improving performance and efficiency. Claude Think Tool: Introduced the Claude Think tool , following the specified implementation guide. \\u200b 2025-03-21 v1.1.15 \\u200b 1.1.15 \\u200b Improvements: Tool Result Caching: Added caching of selected searchers and scrapers. This is only intended for testing and should greatly improve iteration speed, prevent rate limits and reduce costs (where applicable) when testing agents. Applies to: DuckDuckGoTools ExaTools FirecrawlTools GoogleSearchtools HackernewsTools NewspaperTools Newspaper4kTools Websitetools YFinanceTools Show tool calls : Improved how tool calls are displayed when print_response and aprint_response is used. They are now displayed in a separate panel different from response panel. It can also be used in conjunction in response_model . \\u200b 2025-03-20 v1.1.14 \\u200b 1.1.14 - Teams Revamp \\u200b New Features: Teams Revamp : Announcing a new iteration of Agent teams with the following features: Create a Team in one of 3 modes: “Collaborate”, “Coordinate” or “Route”. Various improvements have been made that was broken with the previous teams implementation. Including returning structured output from member agents (for “route” mode), passing images, audio and video to member agents, etc. It has added features like “agentic shared context” between team members and sharing of individual team member responses with other team members. This also comes with a revamp of Agent and Team debug logs. Use debug_mode=True and team.print_response(...) to see it in action. Find the docs here . Please look at the example implementations here . This is the first release. Please give us feedback. Updates and improvements will follow. Support for Agent(team=[]) is still there, but deprecated (see below). LiteLLM: Added LiteLLM support, both as a native implementation and via the OpenAILike interface. \\u200b Improvements: Change structured_output to response_format: Added use_json_mode: bool = False as a parameter of Agent and Team , which in conjunction with response_model=YourModel , is used to indicate whether the agent/team model should be forced to respond in json instead of (now default) structured output. Previous behaviour defaulted to “json-mode”, but since most models now support native structured output, we are now defaulting to native structured output. It is now also much simpler to work with response models, since now only response_model needs to be set. It is not necessary anymore to set structured_output=True to specifically get structured', id='https://docs.agno.com/changelog/overview_6', name='https://docs.agno.com/introduction', meta_data={'url': 'https://docs.agno.com/changelog/overview', 'chunk': 6, 'chunk_size': 4994}, embedder=None, embedding=None, usage=None, reranking_score=None), Document(content=' output from the model. Website Tools + Combined Knowledgebase: Added functionality for WebsiteTools to also update combined knowledgebases. \\u200b Bug Fixes: AgentMemory : Fixed get_message_pairs() fetching incorrect messages. UnionType in Functions : Fixed issue with function parsing where pipe-style unions were used in function parameters. Gemini Array Function Parsing : Fixed issue preventing gemini function parsing to work in some MCP cases. \\u200b Deprecations: Structured Output: Agent.structured_output has been replaced by Agent.use_json_mode . This will be removed in a future major version release. Agent Team: Agent.team is deprecated with the release of our new Teams implementation here . This will be removed in a future major version release. \\u200b 2025-03-14 v1.1.13 \\u200b 1.1.13 \\u200b Improvements: OpenAIResponses File Search : Added support for the built-in “File Search” function from OpenAI. This automatically uploads File objects attached to the agent prompt. OpenAIReponses web citations : Added support to extract URL citations after usage of the built-in “Web Search” tool from OpenAI. Anthropic document citations : Added support to extract document citations from Claude responses when File objects are attached to agent prompts. Cohere Command A : Support and examples added for Coheres new flagship model \\u200b Bug Fixes: Ollama tools : Fixed issues with tools where parameters are not typed. Anthropic Structured Output : Fixed issue affecting Anthropic and Anthropic via Azure where structured output wouldn’t work in some cases. This should make the experience of using structured output for models that don’t natively support it better overall. Also now works with enums as types in the Pydantic model. Google Maps Places : Support from Google for Places API has been changed and this brings it up to date so we can continue to support “search places”. \\u200b 2025-03-13 v1.1.12 \\u200b 1.1.12 \\u200b New Features: Citations : Improved support for capturing, displaying, and storing citations from models, with integration for Gemini and Perplexity. \\u200b Improvements: CalComTools : Improvement to tool Initialization. \\u200b Bug Fixes: MemoryManager : Limit parameter was added fixing a KeyError in MongoMemoryDb. \\u200b 2025-03-13 v1.1.11 \\u200b 1.1.11 \\u200b New Features: OpenAI Responses : Added a new model implementation that supports OpenAI’s Responses API. This includes support for their “websearch” built-in tool. Openweather API Tool: Added tool to get real-time weather information. \\u200b Improvements: Storage Refactor: Merged agent and workflow storage classes to align storage better for agents, teams and workflows. This change is backwards compatible and should not result in any disruptions. \\u200b 2025-03-12 v1.1.10 \\u200b 1.1.10 \\u200b New Features: File Prompts : Introduced a new File type that can be added to prompts and will be sent to the model providers. Only Gemini and Anthropic Claude supported for now. LMStudio: Added support for LMStudio as a model provider. See the docs . AgentQL Tools : Added tools to support AgentQL for connecting agents to websites for scraping, etc. See the docs . Browserbase Tool: Added Browserbase tool. \\u200b Improvements: Cohere Vision : Added support for image understanding with Cohere models. See this cookbook to try it out. Embedder defaults logging : Improved logging when using the default OpenAI embedder. \\u200b Bug Fixes: Ollama Embedder : Fix for getting embeddings from Ollama across different versions. \\u200b 2025-03-06 v1.1.9 \\u200b 1.1.9 \\u200b New Features: IBM Watson X: Added support for IBM Watson X as a model provider. Find the docs here . DeepInfra : Added support for DeepInfra . Find the docs here . Support for MCP : Introducing MCPTools along with examples for using MCP with Agno agents. \\u200b Bug Fixes: Mistral with reasoning : Fixed cases where Mistral would fail when reasoning models from other providers generated reasoning content. \\u200b 2025-03-03 v1.1.8 \\u200b 1.1.8 \\u200b New Features: Video File Upload on Playground : You can now upload video files and have a model interpret the video. This feature is supported only by select Gemini models with video processing capabilities. \\u200b Bug Fixes: Huggingface : Fixed multiple issues with the Huggingface model integration. Tool calling is now fully supported in non-streaming cases. Gemini : Resolved an issue with manually setting the assistant role and tool call result metrics. OllamaEmbedder : Fixed issue where no embeddings were returned. \\u200b 2025-02-26 v1.1.7 \\u200b 1.1.7 \\u200b New Features: Audio File Upload on Playground : You can now upload audio files and have a model interpret the audio, do sentiment analysis, provide an audio transcription, etc. \\u200b Bug Fixes: Claude Thinking Streaming : Fix Claude thinking when streaming is active, as well as for async runs. \\u200b 2025-02-24 v1.1.6 \\u200b 1.1.6 \\u200b New Features: - Claude 3.7 Support: Added support for the latest Claude 3.7 Sonnet model \\u200b Bug Fixes: - Claude Tool Use : Fixed an issue where tools and content could not be used in the same block when interacting with Claude models. \\u200b', id='https://docs.agno.com/changelog/overview_7', name='https://docs.agno.com/introduction', meta_data={'url': 'https://docs.agno.com/changelog/overview', 'chunk': 7, 'chunk_size': 4993}, embedder=None, embedding=None, usage=None, reranking_score=None), Document(content=' 2025-02-24 v1.1.5 \\u200b 1.1.5 \\u200b New Features: Audio Responses: Agents can now deliver audio responses (both with streaming and non-streaming). The audio is in the agent.run_response.response_audio . This only works with OpenAIChat with the gpt-4o-audio-preview model. See their docs for more on how it works. For example from agno.agent import Agent from agno.models.openai import OpenAIChat from agno.utils.audio import write_audio_to_file agent = Agent( model =OpenAIChat( id = \"gpt-4o-audio-preview\" , modalities =[ \"text\" , \"audio\" ], # Both text and audio responses are provided. audio ={ \"voice\" : \"alloy\" , \"format\" : \"wav\" }, ), ) agent.print_response( \"Tell me a 5 second story\" ) if agent.run_response.response_audio is not None : write_audio_to_file( audio =agent.run_response.response_audio.base64_audio, filename = str (filename) ) See the audio_conversation_agent cookbook to test it out on the Agent Playground. Image understanding support for Together.ai and XAi : You can now give images to agents using models from XAi and Together.ai. \\u200b Improvements: Automated Tests: Added integration tests for all models. Most of these will be run on each pull request, with a suite of integration tests run before a new release is published. Grounding and Search with Gemini: Grounding and Search can be used to improve the accuracy and recency of responses from the Gemini models. \\u200b Bug Fixes: Structured output updates : Fixed various cases where native structured output was not used on models. Ollama tool parsing : Fixed cases for Ollama with tools with optional parameters. Gemini Memory Summariser : Fixed cases where Gemini models were used as the memory summariser. Gemini auto tool calling : Enabled automatic tool calling when tools are provided, aligning behavior with other models. FixedSizeChunking issue with overlap: Fixed issue where chunking would fail if overlap was set. Claude tools with multiple types : Fixed an issue where Claude tools would break when handling a union of types in parameters. JSON response parsing : Fixed cases where JSON model responses returned quoted strings within dictionary values. \\u200b 2025-02-17 v1.1.4 \\u200b 1.1.4 \\u200b Improvements: Gmail Tools : Added get_emails_by_thread and send_email_reply methods to GmailTools . \\u200b Bug Fixes: Gemini List Parameters : Fixed an issue with functions using list-type parameters in Gemini. Gemini Safety Parameters : Fixed an issue with passing safety parameters in Gemini. ChromaDB Multiple Docs: Fixed an issue with loading multiple documents into ChromaDB. Agentic Chunking: Fixed an issue where OpenAI was required for chunking even when a model was provided. \\u200b 2025-02-16 v1.1.3 \\u200b 1.1.3 \\u200b Bug Fixes: Gemini Tool-Call History : Fixed an issue where Gemini rejected tool-calls from historic messages. \\u200b 2025-02-15 v1.1.2 \\u200b 1.1.2 \\u200b Improvements: Reasoning with o3 Models : Reasoning support added for OpenAI’s o3 models. Gemini embedder update: Updated the GeminiEmbedder to use the new Google’s genai SDK . This update introduces a slight change in the interface: # Before embeddings = GeminiEmbedder( \"models/text-embedding-004\" ).get_embedding( \"The quick brown fox jumps over the lazy dog.\" ) # After embeddings = GeminiEmbedder( \"text-embedding-004\" ).get_embedding( \"The quick brown fox jumps over the lazy dog.\" ) \\u200b Bug Fixes: Singlestore Fix: Fixed an issue where querying SingleStore caused the embeddings column to return in binary format. MongoDB Vectorstore Fix: Fixed multiple issues in MongoDB, including duplicate creation and deletion of collections during initialization. All known issues have been resolved. LanceDB Fix: Fixed various errors in LanceDB and added on_bad_vectors as a parameter. \\u200b 2025-02-14 v1.1.1 \\u200b 1.1.1 \\u200b Improvements: File / Image Uploads on Agent UI: Agent UI now supports file and image uploads with prompts. Supported file formats: .pdf , .csv , .txt , .docx , .json Supported image formats: .png , .jpeg , .jpg , .webp Firecrawl Custom API URL : Allowed users to set a custom API URL for Firecrawl. Updated ModelsLabTools Toolkit Constructor : The constructor in /libs/agno/tools/models_labs.py has been updated to accommodate audio generation API calls. This is a breaking change, as the parameters for the ModelsLabTools class have changed. The url and fetch_url parameters have been removed, and API URLs are now decided based on the file_type provided by the user. MODELS_LAB_URLS = { \"MP4\" : \"https://modelslab.com/api/v6/video/text2video\" , \"MP3\" : \"https://modelslab.com/api/v6/voice/music_gen\" , \"GIF\" : \"https://modelslab.com/api/v6/video/text2video\" , } MODELS_LAB_FETCH_URLS = { \"MP4\" : \"https://modelslab.com/api/v6/video/fetch\" , \"MP3\" : \"https://modelslab.com/api/v6/voice/fetch\" , \"GIF\" : \"https://modelslab.com/api/v6/video/fetch\" , } The FileType enum now includes MP3 type: class FileType ( str , Enum ): MP4 = \" mp4 \" GIF = \" gif \" MP3 = \" mp3 \" \\u200b Bug Fixes: Gemini functions with no parameters: Addressed an issue where Gemini would reject function', id='https://docs.agno.com/changelog/overview_8', name='https://docs.agno.com/introduction', meta_data={'url': 'https://docs.agno.com/changelog/overview', 'chunk': 8, 'chunk_size': 4992}, embedder=None, embedding=None, usage=None, reranking_score=None), Document(content=' declarations with empty properties. Fix exponential memory growth : Fixed certain cases where the agent memory would grow exponentially. Chroma DB: Fixed various issues related to metadata on insertion and search. Gemini Structured Output : Fixed a bug where Gemini would not generate structured output correctly. MistralEmbedder: Fixed issue with instantiation of MistralEmbedder . Reasoning : Fixed an issue with setting reasoning models. Audio Response: Fixed an issue with streaming audio artefacts to the playground. \\u200b 2025-02-12 v1.1.0 \\u200b 1.1.0 - Models Refactor and Cloud Support \\u200b Model Improvements: Models Refactor : A complete overhaul of our models implementation to improve on performance and to have better feature parity across models. This improves metrics and visibility on the Agent UI as well. All models now support async-await, with the exception of AwsBedrock . Azure AI Foundry : We now support all models on Azure AI Foundry. Learn more here .. AWS Bedrock Support : Our redone AWS Bedrock implementation now supports all Bedrock models. It is important to note which models support which features . Gemini via Google SDK : With the 1.0.0 release of Google’s genai SDK we could improve our previous implementation of Gemini . This will allow for easier integration of Gemini features in future. Model Failure Retries: We added better error handling of third-party errors (e.g. Rate-Limit errors) and the agent will now optionally retry with exponential backoff if exponential_backoff is set to True . \\u200b Other Improvements Exa Answers Support : Added support for the Exa answers capability. GoogleSearchTools : Updated the name of GoogleSearch to GoogleSearchTools for consistency. \\u200b Deprecation Our Gemini implementation directly on the Vertex API has been replaced by the Google SDK implementation of Gemini . Our Gemini implementation via the OpenAI client has been replaced by the Google SDK implementation of Gemini . Our OllamaHermes has been removed as the implementation of Ollama was improved. \\u200b Bug Fixes Team Members Names : Fixed a bug where teams where team members have non-aphanumeric characters in their names would cause exceptions. \\u200b 2025-02-07 v1.0.8 \\u200b 1.0.8 \\u200b New Features: Perplexity Model : We now support Perplexity as a model provider. Todoist Toolkit: Added a toolkit for managing tasks on Todoist. JSON Reader : Added a JSON file reader for use in knowledge bases. \\u200b Improvements: LanceDb : Implemented name_exists function for LanceDb. \\u200b Bug Fixes: Storage growth bug: Fixed a bug with duplication of run_messages.messages for every run in storage. \\u200b 2025-02-05 v1.0.7 \\u200b 1.0.7 \\u200b New Features: Google Sheets Toolkit : Added a basic toolkit for reading, creating and updating Google sheets. Weviate Vector Store : Added support for Weviate as a vector store. \\u200b Improvements: Mistral Async : Mistral now supports async execution via agent.arun() and agent.aprint_response() . Cohere Async : Cohere now supports async execution via agent.arun() and agent.aprint_response() . \\u200b Bug Fixes: Retriever as knowledge source : Added small fix and examples for using the custom retriever parameter with an agent. \\u200b 2025-02-05 v1.0.6 \\u200b 1.0.6 \\u200b New Features: Google Maps Toolkit : Added a rich toolkit for Google Maps that includes business discovery, directions, navigation, geocode locations, nearby places, etc. URL reader and knowledge base : Added reader and knowledge base that can process any URL and store the text contents in the document store. \\u200b Bug Fixes: Zoom tools fix: Zoom tools updated to include the auth step and other misc fixes. Github search_repositories pagination : Pagination did not work correctly and this was fixed. \\u200b 2025-02-03 v1.0.5 \\u200b 1.0.5 \\u200b New Features: Gmail Tools: Add tools for Gmail, including mail search, sending mails, etc. \\u200b Improvements: Exa Toolkit Upgrade: Added find_similar to ExaTools Claude Async: Claude models can now be used with await agent.aprint_response() and await agent.arun() . Mistral Vision: Mistral vision models are now supported. Various examples were added to illustrate example . \\u200b 2025-02-02 v1.0.4 \\u200b 1.0.4 \\u200b Bug Fixes: Claude Tool Invocation: Fixed issue where Claude was not working with tools that have no parameters. \\u200b 2025-01-31 v1.0.3 \\u200b 1.0.3 \\u200b Improvements: OpenAI Reasoning Parameter: Added a reasoning parameter to OpenAI models. \\u200b 2025-01-31 v1.0.2 \\u200b 1.0.2 \\u200b Improvements: Model Client Caching: Made all models cache the client instantiation, improving Agno agent instantiation time XTools: Renamed TwitterTools to XTools and updated capabilities to be compatible with Twitter API v2. \\u200b Bug Fixes: Agent Dataclass Compatibility: Removed slots=True from the agent dataclass decorator, which was not compatible with Python < 3.10. AzureOpenAIEmbedder: Made AzureOpenAIEmbedder a dataclass to match other embedders. \\u200b 2025-01-31 v1.0.1 \\u200b 1.0.1 \\u200b Improvement: Mistral Model Caching: Enabled caching for Mistral models. \\u200b 2025-01-30 v1.0.0 \\u200b 1.0.0 - Agno This is the major refactor from', id='https://docs.agno.com/changelog/overview_9', name='https://docs.agno.com/introduction', meta_data={'url': 'https://docs.agno.com/changelog/overview', 'chunk': 9, 'chunk_size': 4994}, embedder=None, embedding=None, usage=None, reranking_score=None), Document(content=' phidata to agno , released with the official launch of Agno AI. See the migration guide for additional guidance. \\u200b Interface Changes: phi.model.x → agno.models.x phi.knowledge_base.x → agno.knowledge.x (applies to all knowledge bases) phi.document.reader.xxx → agno.document.reader.xxx_reader (applies to all document readers) All Agno toolkits are now suffixed with Tools . E.g. DuckDuckGo → DuckDuckGoTools Multi-modal interface updates: agent.run(images=[]) and agent.print_response(images=[]) is now of type Image class Image ( BaseModel ): url: Optional[ str ] = None # Remote location for image filepath: Optional[Union[Path, str ]] = None # Absolute local location for image content: Optional[Any] = None # Actual image bytes content detail: Optional[ str ] = None # low, medium, high or auto (per OpenAI spec https://platform.openai.com/docs/guides/vision?lang=node#low-or-high-fidelity-image-understanding) id : Optional[ str ] = None agent.run(audio=[]) and agent.print_response(audio=[]) is now of type Audio class Audio ( BaseModel ): filepath: Optional[Union[Path, str ]] = None # Absolute local location for audio content: Optional[Any] = None # Actual audio bytes content format : Optional[ str ] = None agent.run(video=[]) and agent.print_response(video=[]) is now of type Video class Video ( BaseModel ): filepath: Optional[Union[Path, str ]] = None # Absolute local location for video content: Optional[Any] = None # Actual video bytes content RunResponse.images is now a list of type ImageArtifact class ImageArtifact ( Media ): id : str url: str # Remote location for file alt_text: Optional[ str ] = None RunResponse.audio is now a list of type AudioArtifact class AudioArtifact ( Media ): id : str url: Optional[ str ] = None # Remote location for file base64_audio: Optional[ str ] = None # Base64-encoded audio data length: Optional[ str ] = None mime_type: Optional[ str ] = None RunResponse.videos is now a list of type VideoArtifact class VideoArtifact ( Media ): id : str url: str # Remote location for file eta: Optional[ str ] = None length: Optional[ str ] = None RunResponse.response_audio is now of type AudioOutput class AudioOutput ( BaseModel ): id : str content: str # Base64 encoded expires_at: int transcript: str Models: Hermes → OllamaHermes AzureOpenAIChat → AzureOpenAI CohereChat → Cohere DeepSeekChat → DeepSeek GeminiOpenAIChat → GeminiOpenAI HuggingFaceChat → HuggingFace Embedders now all take id instead of model as a parameter. For example db_url = \"postgresql+psycopg://ai:ai@localhost:5532/ai\" knowledge_base = PDFUrlKnowledgeBase( urls =[ \"https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf\" ], vector_db =PgVector( table_name = \"recipes\" , db_url =db_url, embedder =OllamaEmbedder( id = \"llama3.2\" , dimensions = 3072 ), ), ) knowledge_base.load( recreate = True ) Agent Storage class PgAgentStorage → PostgresDbAgentStorage SqlAgentStorage → SqliteDbAgentStorage MongoAgentStorage → MongoDbAgentStorage S2AgentStorage → SingleStoreDbAgentStorage Workflow Storage class SqlWorkflowStorage → SqliteDbWorkflowStorage PgWorkflowStorage → PostgresDbWorkflowStorage MongoWorkflowStorage → MongoDbWorkflowStorage Knowledge Base phi.knowledge.pdf.PDFUrlKnowledgeBase → agno.knowledge.pdf_url.PDFUrlKnowledgeBase phi.knowledge.csv.CSVUrlKnowledgeBase → agno.knowledge.csv_url.CSVUrlKnowledgeBase Readers phi.document.reader.arxiv → agno.document.reader.arxiv_reader phi.document.reader.docx → agno.document.reader.docx_reader phi.document.reader.json → agno.document.reader.json_reader phi.document.reader.pdf → agno.document.reader.pdf_reader phi.document.reader.s3.pdf → agno.document.reader.s3.pdf_reader phi.document.reader.s3.text → agno.document.reader.s3.text_reader phi.document.reader.text → agno.document.reader.text_reader phi.document.reader.website → agno.document.reader.website_reader \\u200b Improvements: Dataclasses: Changed various instances of Pydantic models to dataclasses to improve the speed. Moved Embedder class from pydantic to data class \\u200b Removals Removed all references to Assistant Removed all references to llm Removed the PhiTools tool On the Agent class, guidelines , prevent_hallucinations , prevent_prompt_leakage , limit_tool_access , and task has been removed. They can be incorporated into the instructions parameter as you see fit. \\u200b Bug Fixes: Semantic Chunking: Fixed semantic chunking by replacing similarity_threshold param with threshold param. \\u200b New Features: Evals for Agents: Introducing Evals to measure the performance, accuracy, and reliability of your Agents. Was this page helpful? Yes No Suggest edits Raise issue x github discord youtube website Powered by Mintlify Assistant Responses are generated using AI and may contain mistakes.', id='https://docs.agno.com/changelog/overview_10', name='https://docs.agno.com/introduction', meta_data={'url': 'https://docs.agno.com/changelog/overview', 'chunk': 10, 'chunk_size': 4740}, embedder=None, embedding=None, usage=None, reranking_score=None), Document(content='Agno home page Search... Ask AI Discord Community agno-agi / agno agno-agi / agno Search... Navigation Introduction What are Agents? User Guide Examples Workspaces FAQs API reference Changelog Introduction What is Agno? Your first Agents Multi Agent Systems Agent Playground Monitoring & Debugging Community & Support Concepts Agents Teams Models Tools Reasoning Memory Knowledge Chunking Vector DBs Storage Embeddings Evals Workflows Applications Other Agent UI Agent API Observability How to Install & Setup Contributing to Agno Migrate from Phidata to Agno Introduction What are Agents? Copy page Agents are AI programs that operate autonomously. Traditional software follows a pre-programmed sequence of steps. Agents dynamically determine their course of action using a machine learning model , its core components are: Model: controls the flow of execution. It decides whether to reason, act or respond. Tools: enable an Agent to take actions and interact with external systems. Instructions: are how we program the Agent, teaching it how to use tools and respond. Agents also have memory , knowledge , storage and the ability to reason : Reasoning: enables Agents to “think” before responding and “analyze” the results of their actions (i.e. tool calls), this improves reliability and quality of responses. Knowledge: is domain-specific information that the Agent can search at runtime to make better decisions and provide accurate responses (RAG). Knowledge is stored in a vector database and this search at runtime pattern is known as Agentic RAG/Agentic Search. Storage: is used by Agents to save session history and state in a database. Model APIs are stateless and storage enables us to continue conversations from where they left off. This makes Agents stateful, enabling multi-turn, long-term conversations. Memory: gives Agents the ability to store and recall information from previous interactions, allowing them to learn user preferences and personalize their responses. Let’s build a few Agents to see how they work. \\u200b Level 1: Agents with tools and instructions The simplest Agent has a model, a tool and instructions. Let’s build an Agent that can fetch data using the yfinance library, along with instructions to display the results in a table. level_1_agent.py from agno.agent import Agent from agno.models.anthropic import Claude from agno.tools.yfinance import YFinanceTools agent = Agent( model =Claude( id = \"claude-sonnet-4-20250514\" ), tools =[YFinanceTools( stock_price = True )], instructions = \"Use tables to display data. Don\\'t include any other text.\" , markdown = True , ) agent.print_response( \"What is the stock price of Apple?\" , stream = True ) Create a virtual environment, install dependencies, export your API key and run the Agent. 1 Setup your virtual environment Mac Windows uv venv --python 3.12 source .venv/bin/activate 2 Install dependencies Mac Windows uv pip install -U agno anthropic yfinance 3 Export your Anthropic key Mac Windows export ANTHROPIC_API_KEY = sk- *** 4 Run the agent python agent_with_tools.py Set debug_mode=True or export AGNO_DEBUG=true to see the system prompt and user messages. \\u200b Level 2: Agents with knowledge and storage Knowledge: While models have a large amount of training data, we almost always need to give them domain-specific information to make better decisions and provide accurate responses (RAG). We store this information in a vector database and let the Agent search it at runtime. Storage: Model APIs are stateless and Storage drivers save chat history and state to a database. When the Agent runs, it reads the chat history and state from the database and add it to the messages list, resuming the conversation and making the Agent stateful. In this example, we’ll use: UrlKnowledge to load Agno documentation to LanceDB, using OpenAI for embeddings. SqliteStorage to save the Agent’s session history and state in a database. level_2_agent.py from agno.agent import Agent from agno.embedder.openai import OpenAIEmbedder from agno.knowledge.url import UrlKnowledge from agno.models.anthropic import Claude from agno.storage.sqlite import SqliteStorage from agno.vectordb.lancedb import LanceDb, SearchType # Load Agno documentation in a knowledge base # You can also use `https://docs.agno.com/llms-full.txt` for the full documentation knowledge = UrlKnowledge( urls =[ \"https://docs.agno.com/introduction.md\" ], vector_db =LanceDb( uri = \"tmp/lancedb\" , table_name = \"agno_docs\" , search_type =SearchType.hybrid, # Use OpenAI for embeddings embedder =OpenAIEmbedder( id = \"text-embedding-3-small\" , dimensions = 1536 ), ), ) # Store agent sessions in a SQLite database storage = SqliteStorage( table_name = \"agent_sessions\" , db_file = \"tmp/agent.db\" ) agent = Agent( name = \"Agno Assist\" , model =Claude( id = \"claude-sonnet-4-20250514\" ), instructions =[ \"Search your knowledge before answering the question.\" , \"Only include the output in your response. No other text.\" , ], knowledge =knowledge, storage', id='https://docs.agno.com/introduction/agents_1', name='https://docs.agno.com/introduction', meta_data={'url': 'https://docs.agno.com/introduction/agents', 'chunk': 1, 'chunk_size': 4999}, embedder=None, embedding=None, usage=None, reranking_score=None), Document(content=' =storage, add_datetime_to_instructions = True , # Add the chat history to the messages add_history_to_messages = True , # Number of history runs num_history_runs = 3 , markdown = True , ) if __name__ == \"__main__\" : # Load the knowledge base, comment out after first run # Set recreate to True to recreate the knowledge base if needed agent.knowledge.load( recreate = False ) agent.print_response( \"What is Agno?\" , stream = True ) Install dependencies, export your OPENAI_API_KEY and run the Agent 1 Install new dependencies Mac Windows uv pip install -U lancedb tantivy openai sqlalchemy 2 Run the agent python level_2_agent.py \\u200b Level 3: Agents with memory and reasoning Reasoning: enables Agents to “think” & “analyze” , improving reliability and quality. ReasoningTools is one of the best approaches to improve an Agent’s response quality. Memory: enables Agents to classify, store and recall user preferences, personalizing their responses. Memory helps the Agent build personas and learn from previous interactions. level_3_agent.py from agno.agent import Agent from agno.memory.v2.db.sqlite import SqliteMemoryDb from agno.memory.v2.memory import Memory from agno.models.anthropic import Claude from agno.tools.reasoning import ReasoningTools from agno.tools.yfinance import YFinanceTools memory = Memory( # Use any model for creating and managing memories model =Claude( id = \"claude-sonnet-4-20250514\" ), # Store memories in a SQLite database db =SqliteMemoryDb( table_name = \"user_memories\" , db_file = \"tmp/agent.db\" ), # We disable deletion by default, enable it if needed delete_memories = True , clear_memories = True , ) agent = Agent( model =Claude( id = \"claude-sonnet-4-20250514\" ), tools =[ ReasoningTools( add_instructions = True ), YFinanceTools( stock_price = True , analyst_recommendations = True , company_info = True , company_news = True ), ], # User ID for storing memories, `default` if not provided user_id = \"ava\" , instructions =[ \"Use tables to display data.\" , \"Include sources in your response.\" , \"Only include the report in your response. No other text.\" , ], memory =memory, # Let the Agent manage its memories enable_agentic_memory = True , markdown = True , ) if __name__ == \"__main__\" : # This will create a memory that \"ava\\'s\" favorite stocks are NVIDIA and TSLA agent.print_response( \"My favorite stocks are NVIDIA and TSLA\" , stream = True , show_full_reasoning = True , stream_intermediate_steps = True , ) # This will use the memory to answer the question agent.print_response( \"Can you compare my favorite stocks?\" , stream = True , show_full_reasoning = True , stream_intermediate_steps = True , ) Run the Agent python level_3_agent.py You can use the Memory and Reasoning separately, you don’t need to use them together. Was this page helpful? Yes No Suggest edits Raise issue What is Agno? Multi Agent Systems x github discord youtube website Powered by Mintlify On this page Level 1: Agents with tools and instructions Level 2: Agents with knowledge and storage Level 3: Agents with memory and reasoning Assistant Responses are generated using AI and may contain mistakes.', id='https://docs.agno.com/introduction/agents_2', name='https://docs.agno.com/introduction', meta_data={'url': 'https://docs.agno.com/introduction/agents', 'chunk': 2, 'chunk_size': 3124}, embedder=None, embedding=None, usage=None, reranking_score=None), Document(content='Agno home page Search... Ask AI Discord Community agno-agi / agno agno-agi / agno Search... Navigation Introduction Multi Agent Systems User Guide Examples Workspaces FAQs API reference Changelog Introduction What is Agno? Your first Agents Multi Agent Systems Agent Playground Monitoring & Debugging Community & Support Concepts Agents Teams Models Tools Reasoning Memory Knowledge Chunking Vector DBs Storage Embeddings Evals Workflows Applications Other Agent UI Agent API Observability How to Install & Setup Contributing to Agno Migrate from Phidata to Agno Introduction Multi Agent Systems Copy page Teams of Agents working together towards a common goal. \\u200b Level 4: Agent Teams that can reason and collaborate Agents are the atomic unit of work, and work best when they have a narrow scope and a small number of tools. When the number of tools grows beyond what the model can handle or you need to handle multiple concepts, use a team of agents to spread the load. Agno provides an industry leading multi-agent architecture that allows you to build Agent Teams that can reason, collaborate and coordinate. In this example, we’ll build a team of 2 agents to analyze the semiconductor market performance, reasoning step by step. level_4_team.py from agno.agent import Agent from agno.models.anthropic import Claude from agno.models.openai import OpenAIChat from agno.team.team import Team from agno.tools.duckduckgo import DuckDuckGoTools from agno.tools.reasoning import ReasoningTools from agno.tools.yfinance import YFinanceTools web_agent = Agent( name = \"Web Search Agent\" , role = \"Handle web search requests and general research\" , model =OpenAIChat( id = \"gpt-4.1\" ), tools =[DuckDuckGoTools()], instructions = \"Always include sources\" , add_datetime_to_instructions = True , ) finance_agent = Agent( name = \"Finance Agent\" , role = \"Handle financial data requests and market analysis\" , model =OpenAIChat( id = \"gpt-4.1\" ), tools =[YFinanceTools( stock_price = True , stock_fundamentals = True , analyst_recommendations = True , company_info = True )], instructions =[ \"Use tables to display stock prices, fundamentals (P/E, Market Cap), and recommendations.\" , \"Clearly state the company name and ticker symbol.\" , \"Focus on delivering actionable financial insights.\" , ], add_datetime_to_instructions = True , ) reasoning_finance_team = Team( name = \"Reasoning Finance Team\" , mode = \"coordinate\" , model =Claude( id = \"claude-sonnet-4-20250514\" ), members =[web_agent, finance_agent], tools =[ReasoningTools( add_instructions = True )], instructions =[ \"Collaborate to provide comprehensive financial and investment insights\" , \"Consider both fundamental analysis and market sentiment\" , \"Use tables and charts to display data clearly and professionally\" , \"Present findings in a structured, easy-to-follow format\" , \"Only output the final consolidated analysis, not individual agent responses\" , ], markdown = True , show_members_responses = True , enable_agentic_context = True , add_datetime_to_instructions = True , success_criteria = \"The team has provided a complete financial analysis with data, visualizations, risk assessment, and actionable investment recommendations supported by quantitative analysis and market research.\" , ) if __name__ == \"__main__\" : reasoning_finance_team.print_response( \"\"\"Compare the tech sector giants (AAPL, GOOGL, MSFT) performance: 1. Get financial data for all three companies 2. Analyze recent news affecting the tech sector 3. Calculate comparative metrics and correlations 4. Recommend portfolio allocation weights\"\"\" , stream = True , show_full_reasoning = True , stream_intermediate_steps = True , ) Install dependencies and run the Agent team 1 Install dependencies Mac Windows uv pip install -U agno anthropic openai duckduckgo-search yfinance 2 Export your API keys Mac Windows export ANTHROPIC_API_KEY = sk- *** export OPENAI_API_KEY = sk- *** 3 Run the agent team python level_4_team.py \\u200b Level 5: Agentic Workflows with state and determinism Workflows are deterministic, stateful, multi-agent programs built for production applications. We write the workflow in pure python, giving us extreme control over the execution flow. Having built 100s of agentic systems, no framework or step based approach will give you the flexibility and reliability of pure-python . Want loops - use while/for, want conditionals - use if/else, want exceptional handling - use try/except. Because the workflow logic is a python function, AI code editors can vibe code workflows for you. Add https://docs.agno.com as a document source and vibe away. Here’s a simple workflow that caches previous outputs, you control every step: what gets cached, what gets streamed, what gets logged and what gets returned. level_5_workflow.py from typing import Iterator from agno.agent import Agent, RunResponse from agno.models.openai import OpenAIChat from agno.utils.log import logger from agno.utils.pprint import pprint_run_response from agno.workflow import', id='https://docs.agno.com/introduction/multi-agent-systems_1', name='https://docs.agno.com/introduction', meta_data={'url': 'https://docs.agno.com/introduction/multi-agent-systems', 'chunk': 1, 'chunk_size': 4997}, embedder=None, embedding=None, usage=None, reranking_score=None), Document(content=' Workflow class CacheWorkflow ( Workflow ): # Add agents or teams as attributes on the workflow agent = Agent( model =OpenAIChat( id = \"gpt-4o-mini\" )) # Write the logic in the `run()` method def run ( self , message : str ) -> Iterator[RunResponse]: logger.info( f \"Checking cache for \\' { message } \\'\" ) # Check if the output is already cached if self .session_state.get(message): logger.info( f \"Cache hit for \\' { message } \\'\" ) yield RunResponse( run_id = self .run_id, content = self .session_state.get(message) ) return logger.info( f \"Cache miss for \\' { message } \\'\" ) # Run the agent and yield the response yield from self .agent.run(message, stream = True ) # Cache the output after response is yielded self .session_state[message] = self .agent.run_response.content if __name__ == \"__main__\" : workflow = CacheWorkflow() # Run workflow (this is takes ~1s) response: Iterator[RunResponse] = workflow.run( message = \"Tell me a joke.\" ) # Print the response pprint_run_response(response, markdown = True , show_time = True ) # Run workflow again (this is immediate because of caching) response: Iterator[RunResponse] = workflow.run( message = \"Tell me a joke.\" ) # Print the response pprint_run_response(response, markdown = True , show_time = True ) Run the workflow python level_5_workflow.py \\u200b Next Checkout the Agent Playground to interact with your Agents, Teams and Workflows. Learn how to Monitor your Agents, Teams and Workflows. Get help from the Community . Was this page helpful? Yes No Suggest edits Raise issue Your first Agents Agent Playground x github discord youtube website Powered by Mintlify On this page Level 4: Agent Teams that can reason and collaborate Level 5: Agentic Workflows with state and determinism Next Assistant Responses are generated using AI and may contain mistakes.', id='https://docs.agno.com/introduction/multi-agent-systems_2', name='https://docs.agno.com/introduction', meta_data={'url': 'https://docs.agno.com/introduction/multi-agent-systems', 'chunk': 2, 'chunk_size': 1811}, embedder=None, embedding=None, usage=None, reranking_score=None), Document(content='Agno home page Search... Ask AI Discord Community agno-agi / agno agno-agi / agno Search... Navigation Introduction Agent Playground User Guide Examples Workspaces FAQs API reference Changelog Introduction What is Agno? Your first Agents Multi Agent Systems Agent Playground Monitoring & Debugging Community & Support Concepts Agents Teams Models Tools Reasoning Memory Knowledge Chunking Vector DBs Storage Embeddings Evals Workflows Applications Other Agent UI Agent API Observability How to Install & Setup Contributing to Agno Migrate from Phidata to Agno Introduction Agent Playground Copy page Agno provides a beautiful frontend for interacting with your agents and teams. Agent Playground No data is sent to agno.com , all agent data is stored locally in your sqlite database. \\u200b Run Playground Server Locally Let’s run the Playground Server locally so we can chat with our Agents using the Agent UI. Create a file playground.py playground.py from agno.agent import Agent from agno.models.openai import OpenAIChat from agno.playground import Playground, serve_playground_app from agno.storage.sqlite import SqliteStorage from agno.tools.duckduckgo import DuckDuckGoTools from agno.tools.yfinance import YFinanceTools agent_storage: str = \"tmp/agents.db\" web_agent = Agent( name = \"Web Agent\" , model =OpenAIChat( id = \"gpt-4o\" ), tools =[DuckDuckGoTools()], instructions =[ \"Always include sources\" ], # Store the agent sessions in a sqlite database storage =SqliteStorage( table_name = \"web_agent\" , db_file =agent_storage), # Adds the current date and time to the instructions add_datetime_to_instructions = True , # Adds the history of the conversation to the messages add_history_to_messages = True , # Number of history responses to add to the messages num_history_responses = 5 , # Adds markdown formatting to the messages markdown = True , ) finance_agent = Agent( name = \"Finance Agent\" , model =OpenAIChat( id = \"gpt-4o\" ), tools =[YFinanceTools( stock_price = True , analyst_recommendations = True , company_info = True , company_news = True )], instructions =[ \"Always use tables to display data\" ], storage =SqliteStorage( table_name = \"finance_agent\" , db_file =agent_storage), add_datetime_to_instructions = True , add_history_to_messages = True , num_history_responses = 5 , markdown = True , ) app = Playground( agents =[web_agent, finance_agent]).get_app() if __name__ == \"__main__\" : serve_playground_app( \"playground:app\" , reload = True ) Remember to export your OPENAI_API_KEY before running the playground application. Make sure the serve_playground_app() points to the file that contains your Playground app. \\u200b Authenticate with Agno Authenticate with agno.com so your local application can let agno know which port you are running the playground on. Run: No data is sent to agno.com, only that you’re running a playground application at port 7777. ag setup [or] export your AGNO_API_KEY from app.agno.com Mac Windows export AGNO_API_KEY = ag- *** \\u200b Run the Playground Server Install dependencies and run your playground server: pip install openai duckduckgo-search yfinance sqlalchemy \\'fastapi[standard]\\' agno python playground.py \\u200b View the Playground Open the link provided or navigate to http://app.agno.com/playground (login required) Select the localhost:7777 endpoint and start chatting with your agents! Looking for a self-hosted alternative? Looking for a self-hosted alternative? Check out our Open Source Agent UI - A modern Agent interface built with Next.js and TypeScript that works exactly like the Agent Playground. \\u200b Get Started with Agent UI # Create a new Agent UI project npx create-agent-ui@latest # Or clone and run manually git clone https://github.com/agno-agi/agent-ui.git cd agent-ui && pnpm install && pnpm dev The UI will connect to localhost:7777 by default, matching the Playground setup above. Visit GitHub for more details. \\u200b Troubleshooting We have identified that certain browsers may experience compatibility issues with the Agent Playground, potentially resulting in connection errors. \\u200b Brave Browser Users may encounter difficulties connecting to localhost endpoints when using Brave, and the ag setup command might not work as expected. To resolve this issue, please try disabling Brave Shields in your browser settings. \\u200b Safari Browser Similar connection issues have been reported with Safari when attempting to connect to localhost endpoints and running ag setup . While we are actively working on a solution, we kindly recommend using alternative browsers such as Chrome, Firefox, or Edge for the best experience. Was this page helpful? Yes No Suggest edits Raise issue Multi Agent Systems Monitoring & Debugging x github discord youtube website Powered by Mintlify On this page Run Playground Server Locally Authenticate with Agno Run the Playground Server View the Playground Troubleshooting Brave Browser Safari Browser Assistant Responses are generated using AI and may contain mistakes.', id='https://docs.agno.com/introduction/playground_1', name='https://docs.agno.com/introduction', meta_data={'url': 'https://docs.agno.com/introduction/playground', 'chunk': 1, 'chunk_size': 4963}, embedder=None, embedding=None, usage=None, reranking_score=None), Document(content='Agno home page Search... Ask AI Discord Community agno-agi / agno agno-agi / agno Search... Navigation Introduction Monitoring & Debugging User Guide Examples Workspaces FAQs API reference Changelog Introduction What is Agno? Your first Agents Multi Agent Systems Agent Playground Monitoring & Debugging Community & Support Concepts Agents Teams Models Tools Reasoning Memory Knowledge Chunking Vector DBs Storage Embeddings Evals Workflows Applications Other Agent UI Agent API Observability How to Install & Setup Contributing to Agno Migrate from Phidata to Agno Introduction Monitoring & Debugging Copy page Monitor your Agents, Teams and Workflows in real-time. \\u200b Agent Monitoring You can track your Agent in real-time on app.agno.com . \\u200b Authenticate Get your API key from the settings page and set the AGNO_API_KEY env var. export AGNO_API_KEY = your_api_key_here \\u200b Enable Monitoring Enable monitoring for a single agent or globally for all agents by setting AGNO_MONITOR=true . \\u200b For a Specific Agent agent = Agent( markdown = True , monitoring = True ) \\u200b Globally for all Agents export AGNO_MONITOR = true \\u200b Monitor Your Agents Run your agent and view the sessions on the sessions page . 1 Create a file with sample code monitoring.py from agno.agent import Agent agent = Agent( markdown = True , monitoring = True ) agent.print_response( \"Share a 2 sentence horror story\" ) 2 Run your Agent python monitoring.py 3 View your sessions View your sessions at app.agno.com/sessions Facing issues? Check out our troubleshooting guide \\u200b Debug Logs Want to see the system prompt, user messages and tool calls? Agno includes a built-in debugger that will print debug logs in the terminal. Set debug_mode=True on any agent or set AGNO_DEBUG=true in your environment. debug_logs.py from agno.agent import Agent from agno.models.anthropic import Claude from agno.tools.yfinance import YFinanceTools agent = Agent( model =Claude( id = \"claude-sonnet-4-20250514\" ), tools =[YFinanceTools( stock_price = True )], instructions = \"Use tables to display data. Don\\'t include any other text.\" , markdown = True , debug_mode = True , ) agent.print_response( \"What is the stock price of Apple?\" , stream = True ) Run the agent to view debug logs in the terminal: python debug_logs.py \\u200b Agent Registry Agents, Teams and Workflows are collectively referred to as “Components of your Agentic System”. When you run them with monitoring enabled, they are registered with the Agno Platform. This means you can view their metadata, runs and configuration. The Registry acts as a unified dashboard where all your Agno Agents, Teams, Workflows and Apps are displayed, giving you full visibility into your operational environment. Start exploring your Agents, Teams and Workflows at app.agno.com/registry . Was this page helpful? Yes No Suggest edits Raise issue Agent Playground Community & Support x github discord youtube website Powered by Mintlify On this page Agent Monitoring Authenticate Enable Monitoring For a Specific Agent Globally for all Agents Monitor Your Agents Debug Logs Agent Registry Assistant Responses are generated using AI and may contain mistakes.', id='https://docs.agno.com/introduction/monitoring_1', name='https://docs.agno.com/introduction', meta_data={'url': 'https://docs.agno.com/introduction/monitoring', 'chunk': 1, 'chunk_size': 3151}, embedder=None, embedding=None, usage=None, reranking_score=None)]\n"
     ]
    }
   ],
   "source": [
    "for document in knowledge_base.document_lists:\n",
    "    print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d66eb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
