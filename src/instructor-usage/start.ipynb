{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "59662c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from litellm import completion\n",
    "import instructor\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d0b98514",
   "metadata": {},
   "outputs": [],
   "source": [
    "class User(BaseModel):\n",
    "    name: str\n",
    "    age: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5ea7a25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = instructor.from_litellm(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ec4371b",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "de66e4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_LIST=[\"gemini-2.0-flash\", \"gemini-2.0-flash-lite\", \"gemini-1.5-pro\", \"gemini-1.5-flash\",\"gemini-1.5-flash-8b\"]\n",
    "MODEL_NAME = f\"gemini/{MODEL_LIST[4]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d1f47f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "MODEL_NAME = 'deepseek/deepseek-reasoner'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b02d4d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='jack' age=32\n"
     ]
    }
   ],
   "source": [
    "user = client.chat.completions.create(\n",
    "    model=MODEL_NAME, \n",
    "    messages=[{\"role\": \"user\", \"content\": \"jack已经32岁了\"}],\n",
    "    response_model=User,\n",
    "    max_retries= 3,\n",
    ")\n",
    "\n",
    "print(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f8170326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user:name='jack' age=32\n",
      "completion:ModelResponse(id='be5a651c-4771-4fca-9fa5-88855b70f859', created=1747552623, model='deepseek-reasoner', object='chat.completion', system_fingerprint='fp_5417b77867_prod0425fp8', choices=[Choices(finish_reason='stop', index=0, message=Message(content='```json\\n{\\n  \"name\": \"jack\",\\n  \"age\": 32\\n}\\n```', role='assistant', tool_calls=None, function_call=None, reasoning_content='好的，我需要根据用户提供的JSON Schema来解析输入的内容，并生成符合该模式的JSON对象。用户给出的例子是“jack已经32岁了”，对应的正确输出应该包含name和age两个必要字段，其中name是字符串，age是整数。\\n\\n首先，我需要确认输入内容中的相关信息。这句话提到了“jack”和“32岁”。显然，“jack”是名字，对应name属性，类型是字符串。而“32岁”中的32是年龄，对应age属性，类型是整数。因此，正确的JSON对象应该是{\"name\": \"jack\", \"age\": 32}。\\n\\n接下来，我需要检查是否符合给定的JSON Schema的要求。Schema中规定必须包含name和age，且类型分别为string和integer。这里提供的示例数据完全符合这些要求，没有遗漏任何必填字段，且数据类型正确。\\n\\n此外，用户特别强调要返回JSON实例，而不是模式本身，并且要用json代码块包裹。因此，我需要确保输出格式正确，避免包含任何额外的说明或错误信息。\\n\\n最后，确认是否存在可能的其他情况或潜在错误。例如，是否存在年龄非整数的情况，或者名字拼写有误。但根据输入内容，这里的信息明确无误，可以直接提取。因此，生成的JSON是正确的。', provider_specific_fields={'reasoning_content': '好的，我需要根据用户提供的JSON Schema来解析输入的内容，并生成符合该模式的JSON对象。用户给出的例子是“jack已经32岁了”，对应的正确输出应该包含name和age两个必要字段，其中name是字符串，age是整数。\\n\\n首先，我需要确认输入内容中的相关信息。这句话提到了“jack”和“32岁”。显然，“jack”是名字，对应name属性，类型是字符串。而“32岁”中的32是年龄，对应age属性，类型是整数。因此，正确的JSON对象应该是{\"name\": \"jack\", \"age\": 32}。\\n\\n接下来，我需要检查是否符合给定的JSON Schema的要求。Schema中规定必须包含name和age，且类型分别为string和integer。这里提供的示例数据完全符合这些要求，没有遗漏任何必填字段，且数据类型正确。\\n\\n此外，用户特别强调要返回JSON实例，而不是模式本身，并且要用json代码块包裹。因此，我需要确保输出格式正确，避免包含任何额外的说明或错误信息。\\n\\n最后，确认是否存在可能的其他情况或潜在错误。例如，是否存在年龄非整数的情况，或者名字拼写有误。但根据输入内容，这里的信息明确无误，可以直接提取。因此，生成的JSON是正确的。'}))], usage=Usage(completion_tokens=274, prompt_tokens=156, total_tokens=430, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=0, reasoning_tokens=252, rejected_prediction_tokens=None, text_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=128, text_tokens=None, image_tokens=None)))\n"
     ]
    }
   ],
   "source": [
    "user,completion = client.chat.completions.create_with_completion(\n",
    "    model=MODEL_NAME, \n",
    "    messages=[{\"role\": \"user\", \"content\": \"jack已经32岁了\"}],\n",
    "    response_model=User,\n",
    "    max_retries= 3,\n",
    "    api_key=api_key,\n",
    ")\n",
    "\n",
    "print(f'user:{user}')\n",
    "print(f'completion:{completion}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc01190",
   "metadata": {},
   "source": [
    "#### 使用不支持function calling和json output的模型，例如deepseek-r1，使用md_json mode，本质就是提示词工程约束"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6602dd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = instructor.from_litellm(completion,mode=instructor.Mode.MD_JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ab5a1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
